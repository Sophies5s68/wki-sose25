{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b60d2c-df95-47c4-9a97-9400ff2e2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Notebook um sich die Daten genauer anzuschauen'\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import preprocess\n",
    "import importlib\n",
    "import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58986a89-758f-4664-9d87-6cd454988532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../shared_data/training_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33513c34-51f4-4cf7-bc41-382f76b0dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f13b6f-45f6-4dd5-b8ba-4a944b3a7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_channels = channels[0]  # Use the first sample as reference\n",
    "all_same = True  # Flag to track if all are the same\n",
    "\n",
    "for i, ch in enumerate(channels):\n",
    "    if ch != reference_channels:\n",
    "        all_same = False\n",
    "        print(f\"Sample ID {ids[i]} has different channels.\")\n",
    "        extra = set(ch) - set(reference_channels)\n",
    "        missing = set(reference_channels) - set(ch)\n",
    "        if extra:\n",
    "            print(f\"  Extra channels: {extra}\")\n",
    "        if missing:\n",
    "            print(f\"  Missing channels: {missing}\")\n",
    "\n",
    "if all_same:\n",
    "    print(\"Every sample has the same channels.\")\n",
    "    print(reference_channels)\n",
    "    print(len(reference_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bd596-5727-4665-b11e-b822c7bf1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "print(f\"found {n_files} files\")\n",
    "\n",
    "index = 0\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    CNN_dataset.create_cnn_dataset_map(ids, channels, data, sampling_frequencies, reference_systems, eeg_labels, i)\n",
    "    print(f\"created dataset {index}\")\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f424cf5-76ce-4664-ae1b-87071235333d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e68209-9a93-4681-b94c-4ba19b1820ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from wettbewerb import get_3montages\n",
    "\n",
    "# Pakete aus dem Vorlesungsbeispiel\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import ruptures as rpt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from CNN_model import CNN_EEG\n",
    "from preprocess import process_without_mne\n",
    "from features import feature_extraction\n",
    "from CNN_dataset import window_data_evaluate, create_fixed_grid_maps\n",
    "from glob import glob\n",
    "\n",
    "###Signatur der Methode (Parameter und Anzahl return-Werte) darf nicht verändert werden\n",
    "def predict_labels(channels : List[str], data : np.ndarray, fs : float, reference_system: str, model_name : str='model.json') -> Dict[str,Any]:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : List[str]\n",
    "        Namen der übergebenen Kanäle\n",
    "    data : ndarray\n",
    "        EEG-Signale der angegebenen Kanäle\n",
    "    fs : float\n",
    "        Sampling-Frequenz der Signale.\n",
    "    reference_system :  str\n",
    "        Welches Referenzsystem wurde benutzt, \"Bezugselektrode\", nicht garantiert korrekt!\n",
    "    model_name : str\n",
    "        Name eures Models,das ihr beispielsweise bei Abgabe genannt habt. \n",
    "        Kann verwendet werden um korrektes Model aus Ordner zu laden\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : Dict[str,Any]\n",
    "        enthält Vorhersage, ob Anfall vorhanden und wenn ja wo (Onset+Offset)\n",
    "    '''\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Euer Code ab hier  \n",
    "\n",
    "    # Initialisiere Return (Ergebnisse)\n",
    "    seizure_present = True # gibt an ob ein Anfall vorliegt\n",
    "    seizure_confidence = 0.5 # gibt die Unsicherheit des Modells an (optional)\n",
    "    onset = 4.2   # gibt den Beginn des Anfalls an (in Sekunden)\n",
    "    onset_confidence = 0.99 # gibt die Unsicherheit bezüglich des Beginns an (optional)\n",
    "    offset = 999999  # gibt das Ende des Anfalls an (optional)\n",
    "    offset_confidence = 0   # gibt die Unsicherheit bezüglich des Endes an (optional)\n",
    "\n",
    "    # Modell Aufsetzen\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device(\"cpu\")\n",
    "    '''\n",
    "    model = torch.load(model_name, map_location=device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    '''\n",
    "    #Daten vorbereiten\n",
    "    window_size = 4.0\n",
    "    step_size = 1\n",
    "    standard_channels = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "    n_nodes = len(standard_channels)\n",
    "\n",
    "    processed_input = process_without_mne(data, fs, channels, reference_system, fs)\n",
    "    \n",
    "    channel_map = {ch: idx for idx, ch in enumerate(channels)}\n",
    "    pad_data = np.zeros((n_nodes, processed_input.shape[1]))\n",
    "    for j, ch in enumerate(standard_channels):\n",
    "        if ch in channel_map:\n",
    "            pad_data[j] = processed_input[channel_map[ch]]\n",
    "    \n",
    "    windows = window_data_evaluate(pad_data, fs, window_size, step_size)\n",
    "    data_for_class = []\n",
    "    # Feature extraction and brain map calculation\n",
    "    for win in windows:\n",
    "        features = feature_extraction(win, fs) # shape: (n_channels, n_features)\n",
    "        assert not np.isnan(features).any(), \"NaN in features!\"\n",
    "        brain_map = create_fixed_grid_maps(features, channels)\n",
    "        assert not np.isnan(brain_map).any(), \"NaN in brain_map!\"\n",
    "        x = torch.tensor(brain_map, dtype = torch.float)\n",
    "        data_for_class.append(x)\n",
    "        \n",
    "\n",
    "    # Klassifikation\n",
    "    predictions_per_window =[]\n",
    "    with torch.no_grad():\n",
    "        for feature_map in data_for_class:\n",
    "            feature_map = feature_map.unsqueeze(0).to(device)\n",
    "            #output = model(feature_map)\n",
    "            #predicted_class = torch.argmax(output, dim=1).item()\n",
    "            predicted_class = predictions_ensemble(feature_map,model_name,device)\n",
    "            predictions_per_window.append(predicted_class)\n",
    "    \n",
    "    seizure_present = False\n",
    "    '''\n",
    "    if 1 in predictions_per_window:\n",
    "        seizure_present = True\n",
    "        first_idx = predictions_per_window.index(1)\n",
    "        time_first = first_idx * step_size\n",
    "        onset = time_first\n",
    "    '''\n",
    "    for i in range(len(predictions_per_window) - 1):\n",
    "        if predictions_per_window[i] == 1 and predictions_per_window[i + 1] == 1:\n",
    "            seizure_present = True\n",
    "            time_first = i * step_size\n",
    "            onset = time_first\n",
    "            break\n",
    "    '''\n",
    "    # Hier könnt ihr euer vortrainiertes Modell laden (Kann auch aus verschiedenen Dateien bestehen)\n",
    "    model = MyCNN()\n",
    "    model.load_state_dict(torch.load(model_name, map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    # Wende Beispielcode aus Vorlesung an \n",
    "    \n",
    "    _montage, _montage_data, _is_missing = get_3montages(channels, data)\n",
    "    signal_std = np.zeros(len(_montage))\n",
    "    for j, signal_name in enumerate(_montage):\n",
    "        # Ziehe erste Montage des EEG\n",
    "        signal = _montage_data[j]\n",
    "        # Wende Notch-Filter an um Netzfrequenz zu dämpfen\n",
    "        signal_notch = mne.filter.notch_filter(x=signal, Fs=fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
    "        # Wende Bandpassfilter zwischen 0.5Hz und 70Hz um Rauschen aus dem Signal zu filtern\n",
    "        signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
    "        \n",
    "        # Berechne short time fourier transformation des Signal: signal_filtered = filtered signal of channel, fs = sampling frequency, nperseg = length of each segment\n",
    "        # Output f= array of sample frequencies, t = array of segment times, Zxx = STFT of signal\n",
    "        f, t, Zxx = sig.stft(signal_filter, fs, nperseg=fs * 3)\n",
    "        # Berechne Schrittweite der Frequenz\n",
    "        df = f[1] - f[0]\n",
    "        # Berechne Engergie (Betrag) basierend auf Real- und Imaginärteil der STFT\n",
    "        E_Zxx = np.sum(Zxx.real ** 2 + Zxx.imag ** 2, axis=0) * df\n",
    "        \n",
    "        signal_std[j] = np.std(signal_filter)\n",
    "\n",
    "\n",
    "\n",
    "        # Erstelle neues Array in der ersten Iteration pro Patient\n",
    "        if j == 0:\n",
    "            # Initilisiere Array mit Energiesignal des ersten Kanals\n",
    "            E_array = np.array(E_Zxx)\n",
    "        else:\n",
    "            # Füge neues Energiesignal zu vorhandenen Kanälen hinzu (stack it)\n",
    "            E_array = np.vstack((E_array, np.array(E_Zxx)))\n",
    "            \n",
    "    # Berechne Feature zur Seizure Detektion\n",
    "    signal_std_max = signal_std.max()\n",
    "    # Klassifiziere Signal\n",
    "    seizure_present = signal_std_max>th_opt\n",
    "    \n",
    "    # Berechne Gesamtenergie aller Kanäle für jeden Zeitppunkt\n",
    "    E_total = np.sum(E_array, axis=0)\n",
    "    # Berechne Stelle der maximalen Energie\n",
    "    max_index = E_total.argmax()\n",
    "\n",
    "    # Berechne \"changepoints\" der Gesamtenergie\n",
    "    # Falls Maximum am Anfang des Signals ist muss der Onset ebenfalls am Anfang sein und wir können keinen \"changepoint\" berechnen\n",
    "    if max_index == 0:\n",
    "        onset = 0.0\n",
    "        onset_confidence = 0.2\n",
    "        \n",
    "    else:\n",
    "        # Berechne \"changepoint\" mit dem ruptures package\n",
    "        # Setup für  \"linearly penalized segmentation method\" zur Detektion von changepoints im Signal mi rbf cost function\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(E_total)\n",
    "        # Berechne sortierte Liste der changepoints, pen = penalty value\n",
    "        result = algo.predict(pen=10)\n",
    "        #Indices sind ums 1 geshiftet\n",
    "        result1 = np.asarray(result) - 1\n",
    "        # Selektiere changepoints vor Maximum\n",
    "        result_red = result1[result1 < max_index]\n",
    "        # Falls es mindestens einen changepoint gibt nehmen wir den nächsten zum Maximum\n",
    "        if len(result_red)<1:\n",
    "            # Falls keine changepoint gefunden wurde raten wir, dass er \"nahe\" am Maximum ist\n",
    "            print('No changepoint, taking maximum')\n",
    "            onset_index = max_index\n",
    "        else:\n",
    "            # Der changepoint entspricht gerade dem Onset \n",
    "            onset_index = result_red[-1]\n",
    "        # Gebe Onset zurück\n",
    "        onset = t[onset_index]      \n",
    "     \n",
    "     \n",
    "    '''\n",
    "#------------------------------------------------------------------------------  \n",
    "    prediction = {\"seizure_present\":seizure_present,\"seizure_confidence\":seizure_confidence,\n",
    "                   \"onset\":onset,\"onset_confidence\":onset_confidence,\"offset\":offset,\n",
    "                   \"offset_confidence\":offset_confidence}\n",
    "  \n",
    "    return prediction # Dictionary mit prediction - Muss unverändert bleiben!\n",
    "                               \n",
    "                               \n",
    "        \n",
    "def predictions_ensemble(feature,model_name,device):\n",
    "    \n",
    "    file_paths = sorted([os.path.join(model_name, f) for f in os.listdir(model_name) if f.endswith(\".pth\")])\n",
    "\n",
    "    probas = torch.zeros(2).to(device)  # 2 Klassen\n",
    "    with torch.no_grad():\n",
    "        for path in file_paths:\n",
    "            model = torch.load(path, map_location=device)\n",
    "            model.eval()\n",
    "            output = model(feature)  # shape: [1, 2]\n",
    "            probas += torch.softmax(output.squeeze(), dim=0)  # → shape: [2]\n",
    "\n",
    "    prediction = probas / len(file_paths)  # shape: [2]\n",
    "    y_pred = (prediction[1] > 0.5).long()  # ← sicher!\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24367d-a342-4c17-a1d5-eccd50a5550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(\"../shared_data/training_mini\", 99)\n",
    "print(predict_labels(channels[0],data[0],sampling_frequencies[0],reference_systems[0],\"models_strat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbb7cf-78d8-4b95-b127-ff2357b6c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "print(f\"found {n_files} files\")\n",
    "\n",
    "index = 0\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    CNN_dataset.create_cnn_dataset_map(ids, channels, data, sampling_frequencies, reference_systems, eeg_labels, i)\n",
    "    print(f\"created dataset {index}\")\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78630c8a-5990-4cb9-911c-c347132bf62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 6213 files\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "100\t Dateien wurden geladen.\n",
      "13\t Dateien wurden geladen.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'signal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m low \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m nyq\n\u001b[1;32m     48\u001b[0m high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m120\u001b[39m \u001b[38;5;241m/\u001b[39m nyq\n\u001b[0;32m---> 49\u001b[0m b, a \u001b[38;5;241m=\u001b[39m \u001b[43msignal\u001b[49m\u001b[38;5;241m.\u001b[39mbutter(\u001b[38;5;241m4\u001b[39m, [low, high], btype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mband\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m w0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m/\u001b[39m (min_fs \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Normierte Frequenz\u001b[39;00m\n\u001b[1;32m     52\u001b[0m b1, a1 \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39miirnotch(w0, \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'signal' is not defined"
     ]
    }
   ],
   "source": [
    "from wettbewerb import load_references\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "print(f\"found {n_files} files\")\n",
    "\n",
    "index = 0\n",
    "positive_data = []\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    df = pd.DataFrame({\n",
    "    'ids': ids,  \n",
    "    'channels': channels,\n",
    "    'data': data,\n",
    "    'fs' : sampling_frequencies,\n",
    "    'ref' : reference_systems,\n",
    "    'label' : eeg_labels\n",
    "    })\n",
    "    \n",
    "    df_label_1 = df[df['label'] == 1]\n",
    "    positive_data.append(df_label_1)\n",
    "    index = index +1\n",
    "    \n",
    "df_label_1_gesamt = pd.concat(positive_data, ignore_index=True)\n",
    "df_label_1_gesamt.to_csv(\"positive_daten.csv\", index=False)\n",
    "\n",
    "df = pd.read_csv(\"positive_daten.csv\")\n",
    "min_fs = df['fs'].min()\n",
    "for i, row in df.iterrows():\n",
    "    orig_fs = row['fs']\n",
    "    if orig_fs > min_fs:\n",
    "        orig_data = row['data']\n",
    "        orig_len = len(orig_data)\n",
    "        \n",
    "        new_len = int(orig_len * min_fs / orig_fs)\n",
    "        new_data = sc.signal.resample(orig_data, new_len)\n",
    "        df.at[i, 'data'] = new_data\n",
    "        df.at[i, 'fs'] = min_fs \n",
    "    \n",
    "\n",
    "nyq = 0.5 * min_fs\n",
    "low = 1 / nyq\n",
    "high = 120 / nyq\n",
    "b, a = signal.butter(4, [low, high], btype='band')\n",
    "\n",
    "w0 = 60 / (min_fs / 2)  # Normierte Frequenz\n",
    "b1, a1 = signal.iirnotch(w0, 30)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    orig_data = row['data']\n",
    "    band_data = signal.filtfilt(b,a,orig_data)\n",
    "    notch_data = signal.filtfilt(b1,a1,band_data)\n",
    "    df.at[i, 'data'] = notch_data\n",
    "    \n",
    "df_label_1_gesamt.to_csv(\"positive_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301e31c-a523-4f9e-b27e-836633d56fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54315e9e-0367-48cb-bfcc-e87e70c73e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "\n",
    "df = pd.read_csv(\"positive_daten.csv\")\n",
    "min_fs = df['fs'].min()\n",
    "for i, row in df.iterrows():\n",
    "    orig_fs = row['fs']\n",
    "    if orig_fs > min_fs:\n",
    "        orig_data = row['data']\n",
    "        orig_len = len(orig_data)\n",
    "        \n",
    "        new_len = int(orig_len * min_fs / orig_fs)\n",
    "        new_data = sc.signal.resample(orig_data, new_len)\n",
    "        df.at[i, 'data'] = new_data\n",
    "        df.at[i, 'fs'] = min_fs \n",
    "    \n",
    "\n",
    "nyq = 0.5 * min_fs\n",
    "low = 1 / nyq\n",
    "high = 120 / nyq\n",
    "b, a = signal.butter(4, [low, high], btype='band')\n",
    "\n",
    "w0 = 60 / (min_fs / 2)  # Normierte Frequenz\n",
    "b1, a1 = signal.iirnotch(w0, 30)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    orig_data = row['data']\n",
    "    band_data = signal.filtfilt(b,a,orig_data)\n",
    "    notch_data = signal.filtfilt(b1,a1,band_data)\n",
    "    df.at[i, 'data'] = notch_data\n",
    "    \n",
    "df_label_1_gesamt.to_csv(\"positive_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5fa09-b36f-476c-b7d7-6710935410ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"positive_daten.csv\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2ef08-a9fc-4944-a99a-894fa2ac75fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wki-sose25)",
   "language": "python",
   "name": "wki-sose25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
