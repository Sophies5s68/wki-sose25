{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d19449-0e04-421f-bc28-6d1fbc9a40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Folder with all .pt files\n",
    "folder = \"data_features_sep/spectral/win4_step1\"\n",
    "\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Step 1: Load all .pt files\n",
    "for fname in os.listdir(folder):\n",
    "    if not fname.endswith(\".pt\"):\n",
    "        continue\n",
    "    fpath = os.path.join(folder, fname)\n",
    "    \n",
    "    try:\n",
    "        features, label, eeg_id, timestamp = torch.load(fpath)\n",
    "        if isinstance(features, torch.Tensor):\n",
    "            features = features.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {fname}: {e}\")\n",
    "        continue\n",
    "\n",
    "    features_list.append(features)\n",
    "    labels_list.append(label)\n",
    "    \n",
    "X = np.array(features_list)\n",
    "y = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3dfda4-21dd-4719-8d04-97f394519ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wettbewerb import load_references\n",
    "train_folder = \"../shared_data/training_mini\" \n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder,99)\n",
    "idx = ids[0]\n",
    "channel = channels[0]\n",
    "data_s = data[0]\n",
    "fs = sampling_frequencies[0]\n",
    "ref = reference_systems[0]\n",
    "model_abgabe= \"model_abgabe/\"\n",
    "print(len(channel))\n",
    "prediction = predict_labels(channels, data, fs, ref, model_abgabe)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b894de6-5f3d-49fa-a00d-564b11db74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "folder_path = \"data_features_sep/spectral/win4_step1\"\n",
    "\n",
    "# List .pt files\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "print(f\"Found {len(files)} .pt files:\")\n",
    "print(files[:0])  # preview first few\n",
    "\n",
    "sample_file = os.path.join(folder_path, files[0])\n",
    "samples = torch.load(sample_file)\n",
    "print(f\"Loaded {len(samples)} samples from {files[0]}\")\n",
    "print(\"First sample shape and contents:\")\n",
    "\n",
    "# Unpack and print\n",
    "features, label, eeg_id, *rest = samples\n",
    "print(\"Features type:\", type(features))\n",
    "print(\"Features shape:\", features.shape if isinstance(features, (torch.Tensor, np.ndarray)) else \"not array\")\n",
    "print(\"Label:\", label)\n",
    "print(\"EEG ID:\", eeg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a4105-bc5d-4a0c-a70a-8b9b109c7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print available keys in the saved dict\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "# Check shapes and types of important fields\n",
    "print(\"Windows shape:\", data[\"windows\"].shape)           # [T, C, F, T’]\n",
    "print(\"Label (sequence):\", data[\"label\"])\n",
    "print(\"Window labels:\", type(data[\"window_labels\"]), len(data[\"window_labels\"]))\n",
    "print(\"Sample window labels:\", data[\"window_labels\"])    # [T]\n",
    "print(\"EEG ID:\", data[\"eeg_id\"])\n",
    "print(\"Seizure onset:\", data[\"seizure_onset\"])\n",
    "print(\"Seizure offset:\", data[\"seizure_offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37755d1b-14e1-416b-8e79-238161e498c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code um besten F1 Score aus abgespeicherten CSV Dateien herauszusuchen und Gruppierung der Modelle\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "\n",
    "base_path = \"models_newWin\"\n",
    "data_by_category = defaultdict(list)\n",
    "\n",
    "for entry in os.listdir(base_path):\n",
    "    if entry.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    full_path = os.path.join(base_path, entry)\n",
    "    res_file = os.path.join(full_path, \"results\", \"training_metrics.csv\")\n",
    "\n",
    "    if not os.path.isfile(res_file):\n",
    "        continue\n",
    "\n",
    "    category = entry.split(\"_\")[-1] \n",
    "\n",
    "    best_scores = {}\n",
    "    with open(res_file, \"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            fold = int(row[\"fold\"])\n",
    "            f1 = float(row[\"f1_score\"])\n",
    "\n",
    "            if fold not in best_scores or f1 > best_scores[fold][\"f1_score\"]:\n",
    "                best_scores[fold] = {\"f1_score\": f1}\n",
    "\n",
    "    fold_scores = []\n",
    "    for i in range(5): \n",
    "        if i in best_scores:\n",
    "            fold_scores.append(f\"{best_scores[i]['f1_score']:.4f}\")\n",
    "        else:\n",
    "            fold_scores.append(\"\")\n",
    "\n",
    "    data_by_category[category].append((entry, fold_scores))\n",
    "    \n",
    "with open(\"results_parameters.txt\", \"w\") as f:\n",
    "    f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "        \"Bezeichnung\", \"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Fold 5\", \"Avg\"))\n",
    "    f.write(\"-\" * 90 + \"\\n\")\n",
    "\n",
    "    for category, models in sorted(data_by_category.items()):\n",
    "        print_name = \"\"\n",
    "        if category == \"act\": \n",
    "            print_name = \"activation function\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"opt\":\n",
    "            print_name = \"optimizer\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"lr\": \n",
    "            print_name = \"learing rate\"\n",
    "            models = [(label.split(\"_\")[1], val) for label, val in models]\n",
    "        if category == \"bs\": \n",
    "            print_name = \"batch_size\"\n",
    "            models = [(label.split(\"_\")[2], val) for label, val in models]\n",
    "        if category == \"loss\": \n",
    "            print_name = \"loss function\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"flat\": \n",
    "            print_name = \"flat CNN\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        f.write(f\"\\n{print_name}:\\n\")\n",
    "\n",
    "        for label, values in models:\n",
    "            try:\n",
    "                float_values = [float(v) for v in values if v]\n",
    "                avg = sum(float_values) / len(float_values) if float_values else \"\"\n",
    "                avg_str = f\"{avg:.4f}\" if avg != \"\" else \"\"\n",
    "            except ValueError:\n",
    "                avg_str = \"\"\n",
    "\n",
    "            f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "                label, *values, avg_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af946b6f-5a18-4589-bc26-9d7e509219af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(\"montage_datasets/combined/win4_step1/combined_400.pt\", map_location='cpu')\n",
    "\n",
    "# Find the first item with label == 1\n",
    "for item in data:\n",
    "    features, label, sample_id, time = item\n",
    "    if label == 1:\n",
    "        print(\"Found item with label 1:\")\n",
    "        print(\"Features shape:\", features.shape)\n",
    "        print(\"Label:\", label)\n",
    "        print(\"Sample ID:\", sample_id)\n",
    "        print(\"Time:\", time)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c6df79a-a3f8-4884-bd74-0eed49f8eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.39671343,  0.31002456,  1.20167539,  0.61168035, -0.78912795,\n",
      "         0.56392585,  0.78173435,  1.22542846,  0.65210768, -0.59066113,\n",
      "        -0.6107416 , -0.66900684,  1.06112907,  0.45223035, -0.44306134],\n",
      "       [ 2.07237451,  2.0163187 , -0.32710171,  1.74845449,  1.39890744,\n",
      "         1.99441151,  1.55668983, -0.17410813,  1.66426925,  1.62063475,\n",
      "         1.59590003,  1.03053922, -0.86959759, -0.62985493, -0.53864759],\n",
      "       [-0.50184262, -0.04353399,  1.41114218, -0.37794431, -0.2044818 ,\n",
      "        -0.45186591,  0.36822387,  1.20798724, -0.28762193, -0.04417692,\n",
      "        -0.29354535,  0.64624984, -0.78630999, -0.60705251, -0.53864759],\n",
      "       [-0.68282521, -0.50366493, -0.17940142, -0.33128269, -0.86625855,\n",
      "        -0.74481138, -0.39366044, -0.02297837, -0.21150563, -0.95220757,\n",
      "        -0.90680798, -0.97890649,  0.59597551,  1.33618937, -0.15656792],\n",
      "       [-0.69180106, -0.88276054, -0.73129286, -0.13501362,  1.35339536,\n",
      "        -0.77654973, -1.14960137, -0.61434612, -0.19227813,  1.0116624 ,\n",
      "         1.14405145,  1.23338125, -1.25445938, -1.51929399, -0.53864759],\n",
      "       [-0.59261905, -0.8963838 , -1.37502158, -1.51589421, -0.89243451,\n",
      "        -0.58511034, -1.16338623, -1.62198308, -1.62497124, -1.04525153,\n",
      "        -0.92885655, -1.26225697,  1.25326238,  0.96778172,  2.21557204]]), 0, 'aaaaaaac_s001_t000', 0.0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "folder = \"data_new_window/win4_step1\"\n",
    "filename=\"combined_0.pt\"\n",
    "data = torch.load(os.path.join(folder, filename))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f60bc4c-7393-488a-aca4-6f442acb4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Skript testet das vortrainierte Modell\n",
    "\n",
    "\n",
    "@author:  Maurice Rohr, Dirk Schweickard\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from wettbewerb import get_6montages\n",
    "\n",
    "# Pakete aus dem Vorlesungsbeispiel\n",
    "import mne\n",
    "from scipy import signal as sps\n",
    "import ruptures as rpt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from CNN_model import CNN_EEG\n",
    "from new_preprocess import preprocess_signal_with_montages\n",
    "from new_features import window_prediction, features_prediction_grouped\n",
    "#from CNN_dataset import window_data_evaluate, create_fixed_grid_maps\n",
    "from glob import glob\n",
    "from scipy.signal import iirnotch, butter, sosfiltfilt, resample_poly, tf2sos\n",
    "from grouped_features import CNN_EEG_Conv2d_muster\n",
    "\n",
    "\n",
    "###Signatur der Methode (Parameter und Anzahl return-Werte) darf nicht verändert werden\n",
    "def predict_labels(channels : List[str], data : np.ndarray, fs : float, reference_system: str, model_name : str='model.json') -> Dict[str,Any]:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : List[str]\n",
    "        Namen der übergebenen Kanäle\n",
    "    data : ndarray\n",
    "        EEG-Signale der angegebenen Kanäle\n",
    "    fs : float\n",
    "        Sampling-Frequenz der Signale.\n",
    "    reference_system :  str\n",
    "        Welches Referenzsystem wurde benutzt, \"Bezugselektrode\", nicht garantiert korrekt!\n",
    "    model_name : str\n",
    "        Name eures Models,das ihr beispielsweise bei Abgabe genannt habt. \n",
    "        Kann verwendet werden um korrektes Model aus Ordner zu laden\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : Dict[str,Any]\n",
    "        enthält Vorhersage, ob Anfall vorhanden und wenn ja wo (Onset+Offset)\n",
    "    '''\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Euer Code ab hier  \n",
    "\n",
    "    # Initialisiere Return (Ergebnisse)\n",
    "    seizure_present = True # gibt an ob ein Anfall vorliegt\n",
    "    seizure_confidence = 0.5 # gibt die Unsicherheit des Modells an (optional)\n",
    "    onset = 4.2   # gibt den Beginn des Anfalls an (in Sekunden)\n",
    "    onset_confidence = 0.99 # gibt die Unsicherheit bezüglich des Beginns an (optional)\n",
    "    offset = 999999  # gibt das Ende des Anfalls an (optional)\n",
    "    offset_confidence = 0   # gibt die Unsicherheit bezüglich des Endes an (optional)\n",
    "\n",
    "    # Modell Aufsetzen\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #Daten vorbereiten\n",
    "    stft_window_size = 1\n",
    "    stft_overlap = 0.5\n",
    "    window_size = 4\n",
    "    step_size = 1\n",
    "    target_fs = 256\n",
    "    original_fs = fs\n",
    " \n",
    "    \n",
    "    montage_names, montage_data, montage_missing,target_fs = preprocess_signal_with_montages(channels, data,target_fs,original_fs) \n",
    "    \n",
    "    windows, timestamps, used = window_prediction(montage_data, target_fs, window_size, step_size)\n",
    "    data_for_class = []\n",
    "    # Feature extraction and brain map calculation\n",
    "    for win in windows:\n",
    "        features = features_prediction_grouped(win, fs, stft_window_size, stft_overlap) # shape: (n_channels, n_features)\n",
    "        assert not np.isnan(features).any(), \"NaN in features!\"\n",
    "        # x = torch.tensor(features, dtype = torch.float)\n",
    "        data_for_class.append(features)\n",
    "        \n",
    "    # Notfallprüfung\n",
    "    if len(data_for_class) == 0:\n",
    "        return {\n",
    "            \"seizure_present\": False,\n",
    "            \"seizure_confidence\": 0.0,\n",
    "            \"onset\": 0.0,\n",
    "            \"onset_confidence\": 0.0,\n",
    "            \"offset\": 0.0,\n",
    "            \"offset_confidence\": 0.0\n",
    "        }\n",
    "    # Klassifikation\n",
    "    predictions_per_window =[]\n",
    "    with torch.no_grad():\n",
    "        probs = predictions_ensemble(data_for_class ,model_name, device)\n",
    "        predictions_per_window = [int(p > 0.5) for p in probs]\n",
    "\n",
    "    seizure_present = False\n",
    "    seizure_present, onset_candidate = detect_onset(predictions_per_window, timestamps, min_consecutive=2)\n",
    "    if seizure_present:\n",
    "        onset = onset_candidate\n",
    "\n",
    "        \n",
    "#------------------------------------------------------------------------------  \n",
    "    prediction = {\"seizure_present\":seizure_present,\"seizure_confidence\":seizure_confidence,\n",
    "                   \"onset\":onset,\"onset_confidence\":onset_confidence,\"offset\":offset,\n",
    "                   \"offset_confidence\":offset_confidence}\n",
    "  \n",
    "    return prediction # Dictionary mit prediction - Muss unverändert bleiben!\n",
    "                               \n",
    "                               \n",
    "# Methode die mit den 5 abgespeicherten Modellen einen Mehreheitsentscheid macht\n",
    "# 5 Modelle aus Stratified Fold für robustere Vorhersage\n",
    "\n",
    "def predictions_ensemble(data_for_class: List[torch.Tensor], model_name: str, device: torch.device) -> List[float]:\n",
    "    file_paths = sorted([os.path.join(model_name, f) for f in os.listdir(model_name) if f.endswith(\".pth\")])\n",
    "    batch_tensor = torch.stack(data_for_class).to(device)\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for path in file_paths:\n",
    "            model = CNN_EEG_Conv2d_muster(4, 1).to(device)\n",
    "            #model = CNN_EEG(6,1).to(device)\n",
    "            model.load_state_dict(torch.load(path, map_location=device))\n",
    "            model.eval()\n",
    "            outputs = torch.sigmoid(model(batch_tensor)).squeeze(1)\n",
    "            probs.append(outputs.cpu().numpy())  # shape: (num_windows,)\n",
    "\n",
    "    ensemble_probs = np.mean(probs, axis=0)  # Mittelwert pro Fenster\n",
    "\n",
    "\n",
    "    # Sicherstellen, dass es immer eine Liste ist\n",
    "    if np.isscalar(ensemble_probs):\n",
    "        return [ensemble_probs]\n",
    "    else:\n",
    "        return ensemble_probs.tolist()  # Gib Liste von Wahrscheinlichkeiten zurück\n",
    "\n",
    "\n",
    "def detect_onset(predictions, timestamps, min_consecutive=2):\n",
    "    predictions = torch.tensor(predictions)\n",
    "    for i in range(len(predictions) - min_consecutive + 1):\n",
    "        if torch.all(predictions[i:i+min_consecutive] == 1):\n",
    "            return True, timestamps[i]\n",
    "    return False, None\n",
    "\n",
    "\n",
    "\n",
    "def notch_filter(signal, fs, freq=50.0, Q=30.0):\n",
    "    w0 = freq / (fs / 2)\n",
    "    b, a = iirnotch(w0, Q)\n",
    "    sos = tf2sos(b, a)  # Transferfunktion → SOS\n",
    "    return sosfiltfilt(sos, signal, axis=-1)\n",
    "\n",
    "\n",
    "def bandpass_filter(signal, fs, lowcut=1.0, highcut=120.0, order=4):\n",
    "    sos = sps.butter(order, [lowcut, highcut], btype='band', fs=fs, output='sos')\n",
    "    return sosfiltfilt(sos, signal, axis=-1)\n",
    "\n",
    "def resample_signal(signal, original_fs, target_fs=256):\n",
    "    if original_fs == target_fs:\n",
    "        return signal\n",
    "    gcd = np.gcd(int(original_fs), int(target_fs))\n",
    "    up = int(target_fs // gcd)\n",
    "    down = int(original_fs // gcd)\n",
    "    return resample_poly(signal, up, down, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de2fcf64-effb-490f-94c1-4c3a01132c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t Dateien wurden geladen.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../shared_data/training_mini\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m ids, channels, data, sampling_frequencies, reference_systems, eeg_labels \u001b[38;5;241m=\u001b[39m load_references(train_folder,\u001b[38;5;241m99\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msampling_frequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreference_systems\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_abgabe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[3], line 86\u001b[0m, in \u001b[0;36mpredict_labels\u001b[0;34m(channels, data, fs, reference_system, model_name)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(features)\u001b[38;5;241m.\u001b[39many(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN in features!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;66;03m# x = torch.tensor(features, dtype = torch.float)\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     data_for_class\u001b[38;5;241m.\u001b[39mappend(\u001b[43mx\u001b[49m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Notfallprüfung\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_for_class) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "from wettbewerb import load_references\n",
    "train_folder = \"../shared_data/training_mini\"\n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder,99)\n",
    "print(predict_labels(channels[0],data[0],sampling_frequencies[0],reference_systems[0],\"model_abgabe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455fa48-5329-4aa0-97c0-efdb85584194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wki-sose25)",
   "language": "python",
   "name": "wki-sose25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
