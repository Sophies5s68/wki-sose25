{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d19449-0e04-421f-bc28-6d1fbc9a40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Folder with all .pt files\n",
    "folder = \"data_features_sep/spectral/win4_step1\"\n",
    "\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Step 1: Load all .pt files\n",
    "for fname in os.listdir(folder):\n",
    "    if not fname.endswith(\".pt\"):\n",
    "        continue\n",
    "    fpath = os.path.join(folder, fname)\n",
    "    \n",
    "    try:\n",
    "        features, label, eeg_id, timestamp = torch.load(fpath)\n",
    "        if isinstance(features, torch.Tensor):\n",
    "            features = features.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {fname}: {e}\")\n",
    "        continue\n",
    "\n",
    "    features_list.append(features)\n",
    "    labels_list.append(label)\n",
    "    \n",
    "X = np.array(features_list)\n",
    "y = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3dfda4-21dd-4719-8d04-97f394519ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wettbewerb import load_references\n",
    "train_folder = \"../shared_data/training_mini\" \n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder,99)\n",
    "idx = ids[0]\n",
    "channel = channels[0]\n",
    "data_s = data[0]\n",
    "fs = sampling_frequencies[0]\n",
    "ref = reference_systems[0]\n",
    "model_abgabe= \"model_abgabe/\"\n",
    "print(len(channel))\n",
    "prediction = predict_labels(channels, data, fs, ref, model_abgabe)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b894de6-5f3d-49fa-a00d-564b11db74f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "folder_path = \"data_features_sep/spectral/win4_step1\"\n",
    "\n",
    "# List .pt files\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "print(f\"Found {len(files)} .pt files:\")\n",
    "print(files[:0])  # preview first few\n",
    "\n",
    "sample_file = os.path.join(folder_path, files[0])\n",
    "samples = torch.load(sample_file)\n",
    "print(f\"Loaded {len(samples)} samples from {files[0]}\")\n",
    "print(\"First sample shape and contents:\")\n",
    "\n",
    "# Unpack and print\n",
    "features, label, eeg_id, *rest = samples\n",
    "print(\"Features type:\", type(features))\n",
    "print(\"Features shape:\", features.shape if isinstance(features, (torch.Tensor, np.ndarray)) else \"not array\")\n",
    "print(\"Label:\", label)\n",
    "print(\"EEG ID:\", eeg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a4105-bc5d-4a0c-a70a-8b9b109c7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print available keys in the saved dict\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "# Check shapes and types of important fields\n",
    "print(\"Windows shape:\", data[\"windows\"].shape)           # [T, C, F, T’]\n",
    "print(\"Label (sequence):\", data[\"label\"])\n",
    "print(\"Window labels:\", type(data[\"window_labels\"]), len(data[\"window_labels\"]))\n",
    "print(\"Sample window labels:\", data[\"window_labels\"])    # [T]\n",
    "print(\"EEG ID:\", data[\"eeg_id\"])\n",
    "print(\"Seizure onset:\", data[\"seizure_onset\"])\n",
    "print(\"Seizure offset:\", data[\"seizure_offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37755d1b-14e1-416b-8e79-238161e498c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code um besten F1 Score aus abgespeicherten CSV Dateien herauszusuchen und Gruppierung der Modelle\n",
    "\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "\n",
    "base_path = \"models_newWin\"\n",
    "data_by_category = defaultdict(list)\n",
    "\n",
    "for entry in os.listdir(base_path):\n",
    "    if entry.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    full_path = os.path.join(base_path, entry)\n",
    "    res_file = os.path.join(full_path, \"results\", \"training_metrics.csv\")\n",
    "\n",
    "    if not os.path.isfile(res_file):\n",
    "        continue\n",
    "\n",
    "    category = entry.split(\"_\")[-1] \n",
    "\n",
    "    best_scores = {}\n",
    "    with open(res_file, \"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            fold = int(row[\"fold\"])\n",
    "            f1 = float(row[\"f1_score\"])\n",
    "\n",
    "            if fold not in best_scores or f1 > best_scores[fold][\"f1_score\"]:\n",
    "                best_scores[fold] = {\"f1_score\": f1}\n",
    "\n",
    "    fold_scores = []\n",
    "    for i in range(5): \n",
    "        if i in best_scores:\n",
    "            fold_scores.append(f\"{best_scores[i]['f1_score']:.4f}\")\n",
    "        else:\n",
    "            fold_scores.append(\"\")\n",
    "\n",
    "    data_by_category[category].append((entry, fold_scores))\n",
    "    \n",
    "with open(\"results_parameters.txt\", \"w\") as f:\n",
    "    f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "        \"Bezeichnung\", \"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Fold 5\", \"Avg\"))\n",
    "    f.write(\"-\" * 90 + \"\\n\")\n",
    "\n",
    "    for category, models in sorted(data_by_category.items()):\n",
    "        print_name = \"\"\n",
    "        if category == \"act\": \n",
    "            print_name = \"activation function\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"opt\":\n",
    "            print_name = \"optimizer\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"lr\": \n",
    "            print_name = \"learing rate\"\n",
    "            models = [(label.split(\"_\")[1], val) for label, val in models]\n",
    "        if category == \"bs\": \n",
    "            print_name = \"batch_size\"\n",
    "            models = [(label.split(\"_\")[2], val) for label, val in models]\n",
    "        if category == \"loss\": \n",
    "            print_name = \"loss function\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"flat\": \n",
    "            print_name = \"flat CNN\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        f.write(f\"\\n{print_name}:\\n\")\n",
    "\n",
    "        for label, values in models:\n",
    "            try:\n",
    "                float_values = [float(v) for v in values if v]\n",
    "                avg = sum(float_values) / len(float_values) if float_values else \"\"\n",
    "                avg_str = f\"{avg:.4f}\" if avg != \"\" else \"\"\n",
    "            except ValueError:\n",
    "                avg_str = \"\"\n",
    "\n",
    "            f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "                label, *values, avg_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af946b6f-5a18-4589-bc26-9d7e509219af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the data\n",
    "data = torch.load(\"montage_datasets/combined/win4_step1/combined_400.pt\", map_location='cpu')\n",
    "\n",
    "# Find the first item with label == 1\n",
    "for item in data:\n",
    "    features, label, sample_id, time = item\n",
    "    if label == 1:\n",
    "        print(\"Found item with label 1:\")\n",
    "        print(\"Features shape:\", features.shape)\n",
    "        print(\"Label:\", label)\n",
    "        print(\"Sample ID:\", sample_id)\n",
    "        print(\"Time:\", time)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6df79a-a3f8-4884-bd74-0eed49f8eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "folder = \"data_new_window/win4_step1\"\n",
    "filename=\"combined_0.pt\"\n",
    "data = torch.load(os.path.join(folder, filename))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f60bc4c-7393-488a-aca4-6f442acb4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Skript testet das vortrainierte Modell\n",
    "\n",
    "\n",
    "@author:  Maurice Rohr, Dirk Schweickard\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from wettbewerb import get_6montages\n",
    "\n",
    "# Pakete aus dem Vorlesungsbeispiel\n",
    "import mne\n",
    "from scipy import signal as sps\n",
    "import ruptures as rpt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from CNN_model import CNN_EEG\n",
    "from new_preprocess import preprocess_signal_with_montages\n",
    "from new_features import window_prediction, features_prediction_grouped\n",
    "#from CNN_dataset import window_data_evaluate, create_fixed_grid_maps\n",
    "from glob import glob\n",
    "from scipy.signal import iirnotch, butter, sosfiltfilt, resample_poly, tf2sos\n",
    "from grouped_features import CNN_EEG_Conv2d_muster\n",
    "\n",
    "\n",
    "###Signatur der Methode (Parameter und Anzahl return-Werte) darf nicht verändert werden\n",
    "def predict_labels(channels : List[str], data : np.ndarray, fs : float, reference_system: str, model_name : str='model.json') -> Dict[str,Any]:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : List[str]\n",
    "        Namen der übergebenen Kanäle\n",
    "    data : ndarray\n",
    "        EEG-Signale der angegebenen Kanäle\n",
    "    fs : float\n",
    "        Sampling-Frequenz der Signale.\n",
    "    reference_system :  str\n",
    "        Welches Referenzsystem wurde benutzt, \"Bezugselektrode\", nicht garantiert korrekt!\n",
    "    model_name : str\n",
    "        Name eures Models,das ihr beispielsweise bei Abgabe genannt habt. \n",
    "        Kann verwendet werden um korrektes Model aus Ordner zu laden\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : Dict[str,Any]\n",
    "        enthält Vorhersage, ob Anfall vorhanden und wenn ja wo (Onset+Offset)\n",
    "    '''\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Euer Code ab hier  \n",
    "\n",
    "    # Initialisiere Return (Ergebnisse)\n",
    "    seizure_present = True # gibt an ob ein Anfall vorliegt\n",
    "    seizure_confidence = 0.5 # gibt die Unsicherheit des Modells an (optional)\n",
    "    onset = 4.2   # gibt den Beginn des Anfalls an (in Sekunden)\n",
    "    onset_confidence = 0.99 # gibt die Unsicherheit bezüglich des Beginns an (optional)\n",
    "    offset = 999999  # gibt das Ende des Anfalls an (optional)\n",
    "    offset_confidence = 0   # gibt die Unsicherheit bezüglich des Endes an (optional)\n",
    "\n",
    "    # Modell Aufsetzen\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #Daten vorbereiten\n",
    "    stft_window_size = 1\n",
    "    stft_overlap = 0.5\n",
    "    window_size = 4\n",
    "    step_size = 1\n",
    "    target_fs = 256\n",
    "    original_fs = fs\n",
    " \n",
    "    \n",
    "    montage_names, montage_data, montage_missing,target_fs = preprocess_signal_with_montages(channels, data,target_fs,original_fs) \n",
    "    \n",
    "    windows, timestamps, used = window_prediction(montage_data, target_fs, window_size, step_size)\n",
    "    data_for_class = []\n",
    "    # Feature extraction and brain map calculation\n",
    "    for win in windows:\n",
    "        features = features_prediction_grouped(win, target_fs, stft_window_size, stft_overlap) # shape: (n_channels, n_features)\n",
    "        assert not np.isnan(features).any(), \"NaN in features!\"\n",
    "        # x = torch.tensor(features, dtype = torch.float)\n",
    "        data_for_class.append(features)\n",
    "        \n",
    "    # Notfallprüfung\n",
    "    if len(data_for_class) == 0:\n",
    "        return {\n",
    "            \"seizure_present\": False,\n",
    "            \"seizure_confidence\": 0.0,\n",
    "            \"onset\": 0.0,\n",
    "            \"onset_confidence\": 0.0,\n",
    "            \"offset\": 0.0,\n",
    "            \"offset_confidence\": 0.0\n",
    "        }\n",
    "    # Klassifikation\n",
    "    predictions_per_window =[]\n",
    "    with torch.no_grad():\n",
    "        probs = predictions_ensemble(data_for_class ,model_name, device)\n",
    "        print(probs)\n",
    "        predictions_per_window = [int(p > 0.5) for p in probs]\n",
    "    print(predictions_per_window)\n",
    "    seizure_present = False\n",
    "    seizure_present, onset_candidate = detect_onset(predictions_per_window, timestamps, min_consecutive=2)\n",
    "    if seizure_present:\n",
    "        onset = onset_candidate\n",
    "\n",
    "        \n",
    "#------------------------------------------------------------------------------  \n",
    "    prediction = {\"seizure_present\":seizure_present,\"seizure_confidence\":seizure_confidence,\n",
    "                   \"onset\":onset,\"onset_confidence\":onset_confidence,\"offset\":offset,\n",
    "                   \"offset_confidence\":offset_confidence}\n",
    "  \n",
    "    return prediction # Dictionary mit prediction - Muss unverändert bleiben!\n",
    "                               \n",
    "                               \n",
    "# Methode die mit den 5 abgespeicherten Modellen einen Mehreheitsentscheid macht\n",
    "# 5 Modelle aus Stratified Fold für robustere Vorhersage\n",
    "\n",
    "def predictions_ensemble(data_for_class: List[torch.Tensor], model_name: str, device: torch.device) -> List[float]:\n",
    "    file_paths = sorted([os.path.join(model_name, f) for f in os.listdir(model_name) if f.endswith(\".pth\")])\n",
    "    batch_tensor = torch.stack(data_for_class).to(device)\n",
    "    probs = []\n",
    "    print(batch_tensor.shape)\n",
    "    with torch.no_grad():\n",
    "        for path in file_paths:\n",
    "            model = CNN_EEG_Conv2d_muster(4, 1).to(device)\n",
    "            #model = CNN_EEG(6,1).to(device)\n",
    "            model.load_state_dict(torch.load(path, map_location=device))\n",
    "            model.eval()\n",
    "            outputs = torch.sigmoid(model(batch_tensor)).squeeze(1)\n",
    "            probs.append(outputs.cpu().numpy())  # shape: (num_windows,)\n",
    "    \n",
    "    ensemble_probs = np.mean(probs, axis=0)  # Mittelwert pro Fenster\n",
    "\n",
    "\n",
    "    # Sicherstellen, dass es immer eine Liste ist\n",
    "    if np.isscalar(ensemble_probs):\n",
    "        return [ensemble_probs]\n",
    "    else:\n",
    "        return ensemble_probs.tolist()  # Gib Liste von Wahrscheinlichkeiten zurück\n",
    "\n",
    "\n",
    "def detect_onset(predictions, timestamps, min_consecutive=2):\n",
    "    predictions = torch.tensor(predictions)\n",
    "    for i in range(len(predictions) - min_consecutive + 1):\n",
    "        if torch.all(predictions[i:i+min_consecutive] == 1):\n",
    "            return True, timestamps[i]\n",
    "    return False, None\n",
    "\n",
    "\n",
    "\n",
    "def notch_filter(signal, fs, freq=50.0, Q=30.0):\n",
    "    w0 = freq / (fs / 2)\n",
    "    b, a = iirnotch(w0, Q)\n",
    "    sos = tf2sos(b, a)  # Transferfunktion → SOS\n",
    "    return sosfiltfilt(sos, signal, axis=-1)\n",
    "\n",
    "\n",
    "def bandpass_filter(signal, fs, lowcut=1.0, highcut=120.0, order=4):\n",
    "    sos = sps.butter(order, [lowcut, highcut], btype='band', fs=fs, output='sos')\n",
    "    return sosfiltfilt(sos, signal, axis=-1)\n",
    "\n",
    "def resample_signal(signal, original_fs, target_fs=256):\n",
    "    if original_fs == target_fs:\n",
    "        return signal\n",
    "    gcd = np.gcd(int(original_fs), int(target_fs))\n",
    "    up = int(target_fs // gcd)\n",
    "    down = int(original_fs // gcd)\n",
    "    return resample_poly(signal, up, down, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de2fcf64-effb-490f-94c1-4c3a01132c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\t Dateien wurden geladen.\n",
      "torch.Size([62, 4, 5, 6])\n",
      "[0.0007442408241331577, 0.002037536818534136, 0.0022136142943054438, 0.0023467254359275103, 0.003173424629494548, 0.005859569180756807, 0.0017331365961581469, 0.007780763320624828, 0.0011126340832561255, 0.0035697058774530888, 0.002272843848913908, 0.0020470269955694675, 0.0003856706607621163, 0.00026252371026203036, 0.00037926743971183896, 0.0027021896094083786, 0.0024915931280702353, 0.001138725783675909, 0.5656313896179199, 0.7637807130813599, 0.951834499835968, 0.9839648008346558, 0.8452165722846985, 0.4677003026008606, 0.34438347816467285, 0.4668019413948059, 0.554216206073761, 0.22616048157215118, 0.3824414610862732, 0.8342410922050476, 0.024385949596762657, 0.03937426954507828, 0.009870604611933231, 0.022095467895269394, 0.027400249615311623, 0.009096087887883186, 0.06572654098272324, 0.002794601721689105, 0.002425892511382699, 0.001297913258895278, 0.0004360087332315743, 0.0004499151255004108, 0.0005708036478608847, 0.0005703642382286489, 0.005375659558922052, 0.012589706107974052, 0.008214730769395828, 0.00498547125607729, 0.0073377699591219425, 0.0006881477311253548, 0.0029820436611771584, 0.0015377482632175088, 0.0002498393296264112, 0.0011650742962956429, 0.0018703698879107833, 0.0018647534307092428, 0.0020214770920574665, 0.0017760924529284239, 0.0008272891864180565, 0.0007266282336786389, 0.0002234768180642277, 0.00023469692678190768]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'seizure_present': True, 'seizure_confidence': 0.5, 'onset': 18.0, 'onset_confidence': 0.99, 'offset': 999999, 'offset_confidence': 0}\n",
      "(1, 19.7015, 28.5202)\n"
     ]
    }
   ],
   "source": [
    "from wettbewerb import load_references\n",
    "train_folder = \"../shared_data/training_mini\"\n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder,90)\n",
    "print(predict_labels(channels[6],data[6],sampling_frequencies[6],reference_systems[6],\"model_abgabe\"))\n",
    "print(eeg_labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455fa48-5329-4aa0-97c0-efdb85584194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e4c51c-f030-4242-bcd6-6e614136a6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf54573-2993-46a1-8662-f83df9dbce59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
