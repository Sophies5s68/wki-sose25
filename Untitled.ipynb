{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d19449-0e04-421f-bc28-6d1fbc9a40a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, fname)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     features, label, eeg_id, timestamp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     19\u001b[0m         features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/wki-sose25/lib/python3.8/site-packages/torch/serialization.py:705\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m--> 705\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    707\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m dispatching to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.jit.load\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directly to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m                           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m silence this warning)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/wki-sose25/lib/python3.8/site-packages/torch/serialization.py:202\u001b[0m, in \u001b[0;36m_opener.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_like):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_like \u001b[38;5;241m=\u001b[39m file_like\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_like\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Folder with all .pt files\n",
    "folder = \"data_features_sep/spectral/win4_step1\"\n",
    "\n",
    "features_list = []\n",
    "labels_list = []\n",
    "\n",
    "# Step 1: Load all .pt files\n",
    "for fname in os.listdir(folder):\n",
    "    if not fname.endswith(\".pt\"):\n",
    "        continue\n",
    "    fpath = os.path.join(folder, fname)\n",
    "    \n",
    "    try:\n",
    "        features, label, eeg_id, timestamp = torch.load(fpath)\n",
    "        if isinstance(features, torch.Tensor):\n",
    "            features = features.numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {fname}: {e}\")\n",
    "        continue\n",
    "\n",
    "    features_list.append(features)\n",
    "    labels_list.append(label)\n",
    "    \n",
    "X = np.array(features_list)\n",
    "y = np.array(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931f92da-6313-462b-ac54-481e74a73758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subfolders or files in spectral:\n",
      " - win8_step8\n",
      " - win10_step5\n",
      " - win10_step10\n",
      " - win30_step15\n",
      " - win20_step10\n",
      " - win30_step30\n",
      " - win4_step1\n",
      " - win20_step20\n",
      " - win4_step2\n",
      " - win8_step4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_path = \"data_features_sep/spectral\"\n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    print(\"Base folder does not exist:\", base_path)\n",
    "else:\n",
    "    print(\"Subfolders or files in spectral:\")\n",
    "    for name in os.listdir(base_path):\n",
    "        print(\" -\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cad5ec6-595c-4e3b-88d0-e0f5a849f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "Skript testet das vortrainierte Modell\n",
    "\n",
    "\n",
    "@author:  Maurice Rohr, Dirk Schweickard\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from wettbewerb import get_3montages\n",
    "\n",
    "# Pakete aus dem Vorlesungsbeispiel\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import ruptures as rpt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from CNN_model import CNN_EEG\n",
    "from new_preprocess import preprocess_signal_with_montages\n",
    "from new_features import window_prediction, feature_extraction_window\n",
    "#from CNN_dataset import window_data_evaluate, create_fixed_grid_maps\n",
    "from glob import glob\n",
    "\n",
    "###Signatur der Methode (Parameter und Anzahl return-Werte) darf nicht verändert werden\n",
    "def predict_labels(channels : List[str], data : np.ndarray, fs : float, reference_system: str, model_name : str='model.json') -> Dict[str,Any]:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : List[str]\n",
    "        Namen der übergebenen Kanäle\n",
    "    data : ndarray\n",
    "        EEG-Signale der angegebenen Kanäle\n",
    "    fs : float\n",
    "        Sampling-Frequenz der Signale.\n",
    "    reference_system :  str\n",
    "        Welches Referenzsystem wurde benutzt, \"Bezugselektrode\", nicht garantiert korrekt!\n",
    "    model_name : str\n",
    "        Name eures Models,das ihr beispielsweise bei Abgabe genannt habt. \n",
    "        Kann verwendet werden um korrektes Model aus Ordner zu laden\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : Dict[str,Any]\n",
    "        enthält Vorhersage, ob Anfall vorhanden und wenn ja wo (Onset+Offset)\n",
    "    '''\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Euer Code ab hier  \n",
    "\n",
    "    # Initialisiere Return (Ergebnisse)\n",
    "    seizure_present = True # gibt an ob ein Anfall vorliegt\n",
    "    seizure_confidence = 0.5 # gibt die Unsicherheit des Modells an (optional)\n",
    "    onset = 4.2   # gibt den Beginn des Anfalls an (in Sekunden)\n",
    "    onset_confidence = 0.99 # gibt die Unsicherheit bezüglich des Beginns an (optional)\n",
    "    offset = 999999  # gibt das Ende des Anfalls an (optional)\n",
    "    offset_confidence = 0   # gibt die Unsicherheit bezüglich des Endes an (optional)\n",
    "\n",
    "    # Modell Aufsetzen\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    #model = torch.load(model_name, map_location=device)\n",
    "    #model.to(device)\n",
    "    #model.eval()\n",
    "    \n",
    "    #Daten vorbereiten\n",
    "    window_size = 4\n",
    "    step_size = 1\n",
    "    target_fs = 256\n",
    "    original_fs = fs\n",
    "    processed_input = preprocess_signal_with_montages(channels, data, target_fs, original_fs)\n",
    "    \n",
    "\n",
    "    \n",
    "    windows, timestamps = window_prediction(processed_input, target_fs, window_size, step_size)\n",
    "    data_for_class = []\n",
    "    # Feature extraction and brain map calculation\n",
    "    for win in windows:\n",
    "        features = feature_extraction_window(win, fs) # shape: (n_channels, n_features)\n",
    "        assert not np.isnan(features).any(), \"NaN in features!\"\n",
    "        x = torch.tensor(features, dtype = torch.float)\n",
    "        data_for_class.append(x)\n",
    "        \n",
    "\n",
    "    # Klassifikation\n",
    "    predictions_per_window =[]\n",
    "    with torch.no_grad():\n",
    "        for feature_matr in data_for_class:\n",
    "            predicted_class = predictions_ensemble(feature_matr ,model_name, device)\n",
    "            predictions_per_window.append(predicted_class)\n",
    "    \n",
    "    seizure_present = False\n",
    "    if 1 in predictions_per_window:\n",
    "        seizure_present = True\n",
    "        first_index = predictions_per_window.index(1)\n",
    "        onset = timestamps[first_index]\n",
    "\n",
    "        \n",
    "#------------------------------------------------------------------------------  \n",
    "    prediction = {\"seizure_present\":seizure_present,\"seizure_confidence\":seizure_confidence,\n",
    "                   \"onset\":onset,\"onset_confidence\":onset_confidence,\"offset\":offset,\n",
    "                   \"offset_confidence\":offset_confidence}\n",
    "  \n",
    "    return prediction # Dictionary mit prediction - Muss unverändert bleiben!\n",
    "                               \n",
    "                               \n",
    "        \n",
    "def predictions_ensemble(feature,model_name,device):\n",
    "    \n",
    "    file_paths = sorted([os.path.join(model_name, f) for f in os.listdir(model_name) if f.endswith(\".pth\")])\n",
    "\n",
    "    probas = torch.zeros(2).to(device)  # 2 Klassen\n",
    "    with torch.no_grad():\n",
    "        for path in file_paths:\n",
    "            model = torch.load(path, map_location=device)\n",
    "            model.eval()\n",
    "            output = model(feature)  # shape: [1, 2]\n",
    "            probas += torch.softmax(output.squeeze(), dim=0)  # → shape: [2]\n",
    "\n",
    "    prediction = probas / len(file_paths)  # shape: [2]\n",
    "    y_pred = (prediction[1] > 0.5).long()  # ← sicher!\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3dfda4-21dd-4719-8d04-97f394519ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t Dateien wurden geladen.\n",
      "19\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m model_abgabe\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_abgabe/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(channel))\n\u001b[0;32m---> 11\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_abgabe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "Cell \u001b[0;32mIn[11], line 74\u001b[0m, in \u001b[0;36mpredict_labels\u001b[0;34m(channels, data, fs, reference_system, model_name)\u001b[0m\n\u001b[1;32m     72\u001b[0m target_fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m     73\u001b[0m original_fs \u001b[38;5;241m=\u001b[39m fs\n\u001b[0;32m---> 74\u001b[0m processed_input \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_signal_with_montages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_fs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_fs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m windows, timestamps \u001b[38;5;241m=\u001b[39m window_prediction(processed_input, target_fs, window_size, step_size)\n\u001b[1;32m     79\u001b[0m data_for_class \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/wki-sose25/new_preprocess.py:47\u001b[0m, in \u001b[0;36mpreprocess_signal_with_montages\u001b[0;34m(channels, data, target_fs, original_fs, ids)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_signal_with_montages\u001b[39m(channels, data, target_fs, original_fs, ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Holt die 6 Montagen aus dem Datensatz\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     montage_names, montage_data, montage_missing \u001b[38;5;241m=\u001b[39m \u001b[43mget_6montages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Signale werden durch einen Notch Filter gefiltert\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     montage_data \u001b[38;5;241m=\u001b[39m notch_filter_iir_filtfilt(montage_data, fs\u001b[38;5;241m=\u001b[39m original_fs)\n",
      "File \u001b[0;32m~/wki-sose25/wettbewerb.py:282\u001b[0m, in \u001b[0;36mget_6montages\u001b[0;34m(channels, data)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03mFunktion berechnet die 6 Montagen Fp1-F3, Fp2-F4, C3-P3, F3-C3, F4-C4, C4-P4 aus den gegebenen Ableitungen (Montagen)\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03mzur selben Referenzelektrode. Falls nicht alle nötigen Elektroden vorhanden sind, wird das entsprechende Signal durch 0 ersetzt. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \n\u001b[1;32m    281\u001b[0m montages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 282\u001b[0m _,m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mshape(data)\n\u001b[1;32m    283\u001b[0m montage_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m6\u001b[39m,m])\n\u001b[1;32m    284\u001b[0m montage_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from wettbewerb import load_references\n",
    "train_folder = \"../shared_data/training_mini\" \n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder,99)\n",
    "idx = ids[0]\n",
    "channel = channels[0]\n",
    "data_s = data[0]\n",
    "fs = sampling_frequencies[0]\n",
    "ref = reference_systems[0]\n",
    "model_abgabe= \"model_abgabe/\"\n",
    "print(len(channel))\n",
    "prediction = predict_labels(channels, data, fs, ref, model_abgabe)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b894de6-5f3d-49fa-a00d-564b11db74f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3257654 .pt files:\n",
      "[]\n",
      "Loaded 4 samples from aaaaajat_s005_t001_win1070_lbl0.pt\n",
      "First sample shape and contents:\n",
      "Features type: <class 'numpy.ndarray'>\n",
      "Features shape: (60,)\n",
      "Label: 0\n",
      "EEG ID: aaaaajat_s005_t001\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "folder_path = \"data_features_sep/spectral/win4_step1\"\n",
    "\n",
    "# List .pt files\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".pt\")]\n",
    "print(f\"Found {len(files)} .pt files:\")\n",
    "print(files[:0])  # preview first few\n",
    "\n",
    "sample_file = os.path.join(folder_path, files[0])\n",
    "samples = torch.load(sample_file)\n",
    "print(f\"Loaded {len(samples)} samples from {files[0]}\")\n",
    "print(\"First sample shape and contents:\")\n",
    "\n",
    "# Unpack and print\n",
    "features, label, eeg_id, *rest = samples\n",
    "print(\"Features type:\", type(features))\n",
    "print(\"Features shape:\", features.shape if isinstance(features, (torch.Tensor, np.ndarray)) else \"not array\")\n",
    "print(\"Label:\", label)\n",
    "print(\"EEG ID:\", eeg_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b91a14-bf25-4dac-8ead-7c5b00d3770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\"Zeitfenster\", \"\", \"\", \"\", \"\", \"\"],\n",
    "    [\"win1_step0.5\", \"0.4637\", \"0.4638\", \"0.4946\", \"0.4689\", \"0.4446\"],\n",
    "    [\"win1_step1\", \"0.4121\", \"0.4334\", \"0.4751\", \"0.3986\", \"0.5466\"],\n",
    "    [\"win2_step2\", \"0.4677\", \"0.4718\", \"0.5421\", \"0.4660\", \"0.4953\"],\n",
    "    [\"win3_step1\", \"0.4974\", \"0.4897\", \"0.5248\", \"0.5710\", \"0.5195\"],\n",
    "    [\"win3_step3\", \"0.4989\", \"0.4956\", \"0.4645\", \"0.4366\", \"0.4696\"],\n",
    "    [\"win4_step1\", \"0.5950\", \"0.4837\", \"0.5394\", \"0.4944\", \"0.5482\"],\n",
    "    [\"win4_step2\", \"0.5000\", \"0.5279\", \"0.5198\", \"0.5406\", \"0.5157\"],\n",
    "    [\"win4_step4\", \"0.4660\", \"0.5118\", \"0.5033\", \"0.4678\", \"0.5220\"],\n",
    "    [\"win8_step4\", \"0.4461\", \"0.4870\", \"0.4609\", \"0.5567\", \"0.4495\"],\n",
    "    [\"win8_step8\", \"0.4534\", \"0.4162\", \"0.5067\", \"0.4592\", \"0.4764\"],\n",
    "    [\"win10_step5\", \"0.4820\", \"0.4832\", \"0.5334\", \"0.4720\", \"0.4999\"],\n",
    "    [\"win10_step10\", \"0.4847\", \"0.4531\", \"0.4840\", \"0.4071\", \"0.4467\"],\n",
    "    [\"win20_step10\", \"0.4116\", \"0.4724\", \"0.4691\", \"0.4663\", \"0.4500\"],\n",
    "    [\"win20_step20\", \"0.4448\", \"0.3850\", \"0.3618\", \"0.4295\", \"0.4134\"],\n",
    "    [\"win30_step15\", \"0.4490\", \"0.4944\", \"0.4645\", \"0.4068\", \"0.3903\"],\n",
    "    [\"win30_step30\", \"0.4110\", \"0.3238\", \"0.3478\", \"0.3889\", \"0.4105\"],\n",
    "]\n",
    "\n",
    "with open(\"results_timeWindows.txt\", \"w\") as f:\n",
    "    # Kopfzeile\n",
    "    f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "        \"Bezeichnung\", \"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Fold 5\", \"Avg\"))\n",
    "    f.write(\"-\" * 90 + \"\\n\")\n",
    "    \n",
    "    # Datenzeilen\n",
    "    for row in data:\n",
    "        label = row[0]\n",
    "        values = row[1:]\n",
    "        try:\n",
    "            # Konvertiere gültige F1-Scores zu floats\n",
    "            float_values = [float(v) for v in values if v.strip()]\n",
    "            avg = sum(float_values) / len(float_values) if float_values else \"\"\n",
    "            avg_str = f\"{avg:.4f}\" if avg != \"\" else \"\"\n",
    "        except ValueError:\n",
    "            avg_str = \"\"\n",
    "        \n",
    "        # Schreibe Zeile mit Durchschnitt\n",
    "        f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "            label, *values, avg_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d564254-04f3-4bfa-9d41-8e208056d412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: aaaaatds_s004_t004_seq.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# === Point to your dataset folder ===\n",
    "dataset_folder = \"raw_dataset/sequences_spectrograms/win4_step2\"\n",
    "file_list = [f for f in os.listdir(dataset_folder) if f.endswith(\".pt\")]\n",
    "\n",
    "# Load one file (e.g., first)\n",
    "sample_path = os.path.join(dataset_folder, file_list[0])\n",
    "data = torch.load(sample_path, map_location='cpu')\n",
    "\n",
    "print(f\"Loaded file: {file_list[20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696a4105-bc5d-4a0c-a70a-8b9b109c7442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: ['windows', 'label', 'window_labels', 'eeg_id', 'timestamps', 'seizure_onset', 'seizure_offset']\n",
      "Windows shape: torch.Size([45, 6, 33, 33])\n",
      "Label (sequence): 0\n",
      "Window labels: <class 'torch.Tensor'> 45\n",
      "Sample window labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "EEG ID: aaaaajpi_s001_t002\n",
      "Seizure onset: 0.0\n",
      "Seizure offset: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print available keys in the saved dict\n",
    "print(\"Keys:\", list(data.keys()))\n",
    "\n",
    "# Check shapes and types of important fields\n",
    "print(\"Windows shape:\", data[\"windows\"].shape)           # [T, C, F, T’]\n",
    "print(\"Label (sequence):\", data[\"label\"])\n",
    "print(\"Window labels:\", type(data[\"window_labels\"]), len(data[\"window_labels\"]))\n",
    "print(\"Sample window labels:\", data[\"window_labels\"])    # [T]\n",
    "print(\"EEG ID:\", data[\"eeg_id\"])\n",
    "print(\"Seizure onset:\", data[\"seizure_onset\"])\n",
    "print(\"Seizure offset:\", data[\"seizure_offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ace8eb-8e86-4689-a649-9104e356cd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.10.2+cu113\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ac13e2-d628-446d-a20e-22688149374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "base_path = \"models_newWin\"\n",
    "data = []\n",
    "\n",
    "# Alle Unterordner im base_path durchgehen\n",
    "for entry in os.listdir(base_path):\n",
    "    if entry.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    full_path = os.path.join(base_path, entry)\n",
    "    res_file = os.path.join(full_path, \"results\", \"training_metrics.csv\")\n",
    "\n",
    "    if not os.path.isfile(res_file):\n",
    "        continue  \n",
    "\n",
    "    best_scores = {}\n",
    "\n",
    "    with open(res_file, \"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            fold = int(row[\"fold\"])\n",
    "            f1 = float(row[\"f1_score\"])\n",
    "\n",
    "            if fold not in best_scores or f1 > best_scores[fold][\"f1_score\"]:\n",
    "                best_scores[fold] = {\n",
    "                    \"f1_score\": f1\n",
    "                }\n",
    "\n",
    "    \n",
    "    fold_scores = []\n",
    "    for i in range(5): \n",
    "        if i in best_scores:\n",
    "            fold_scores.append(f\"{best_scores[i]['f1_score']:.4f}\")\n",
    "        else:\n",
    "            fold_scores.append(\"\")\n",
    "\n",
    "    data.append((entry, fold_scores))\n",
    "\n",
    "\n",
    "with open(\"results_parameters.txt\", \"w\") as f:\n",
    "    # Kopfzeile\n",
    "    f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "        \"Bezeichnung\", \"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Fold 5\", \"Avg\"))\n",
    "    f.write(\"-\" * 90 + \"\\n\")\n",
    "\n",
    "\n",
    "    for label, values in data:\n",
    "        try:\n",
    "            float_values = [float(v) for v in values if v]\n",
    "            avg = sum(float_values) / len(float_values) if float_values else \"\"\n",
    "            avg_str = f\"{avg:.4f}\" if avg != \"\" else \"\"\n",
    "        except ValueError:\n",
    "            avg_str = \"\"\n",
    "\n",
    "        f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "            label, *values, avg_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37755d1b-14e1-416b-8e79-238161e498c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import os\n",
    "\n",
    "base_path = \"models_newWin\"\n",
    "data_by_category = defaultdict(list)\n",
    "\n",
    "for entry in os.listdir(base_path):\n",
    "    if entry.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    full_path = os.path.join(base_path, entry)\n",
    "    res_file = os.path.join(full_path, \"results\", \"training_metrics.csv\")\n",
    "\n",
    "    if not os.path.isfile(res_file):\n",
    "        continue\n",
    "\n",
    "    category = entry.split(\"_\")[-1] \n",
    "\n",
    "    best_scores = {}\n",
    "    with open(res_file, \"r\", newline=\"\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            fold = int(row[\"fold\"])\n",
    "            f1 = float(row[\"f1_score\"])\n",
    "\n",
    "            if fold not in best_scores or f1 > best_scores[fold][\"f1_score\"]:\n",
    "                best_scores[fold] = {\"f1_score\": f1}\n",
    "\n",
    "    fold_scores = []\n",
    "    for i in range(5): \n",
    "        if i in best_scores:\n",
    "            fold_scores.append(f\"{best_scores[i]['f1_score']:.4f}\")\n",
    "        else:\n",
    "            fold_scores.append(\"\")\n",
    "\n",
    "    data_by_category[category].append((entry, fold_scores))\n",
    "    \n",
    "with open(\"results_parameters.txt\", \"w\") as f:\n",
    "    f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "        \"Bezeichnung\", \"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Fold 5\", \"Avg\"))\n",
    "    f.write(\"-\" * 90 + \"\\n\")\n",
    "\n",
    "    for category, models in sorted(data_by_category.items()):\n",
    "        print_name = \"\"\n",
    "        if category == \"act\": \n",
    "            print_name = \"activation function\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"opt\":\n",
    "            print_name = \"optimizer\"\n",
    "            models = [(label.split(\"_\")[0], val) for label, val in models]\n",
    "        if category == \"lr\": \n",
    "            print_name = \"learing rate\"\n",
    "            models = [(label.split(\"_\")[1], val) for label, val in models]\n",
    "        if category == \"bs\": \n",
    "            print_name = \"batch_size\"\n",
    "            models = [(label.split(\"_\")[3], val) for label, val in models]\n",
    "        f.write(f\"\\n{print_name}:\\n\")\n",
    "\n",
    "        for label, values in models:\n",
    "            try:\n",
    "                float_values = [float(v) for v in values if v]\n",
    "                avg = sum(float_values) / len(float_values) if float_values else \"\"\n",
    "                avg_str = f\"{avg:.4f}\" if avg != \"\" else \"\"\n",
    "            except ValueError:\n",
    "                avg_str = \"\"\n",
    "\n",
    "            f.write(\"{:<32} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7} | {:>7}\\n\".format(\n",
    "                label, *values, avg_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af946b6f-5a18-4589-bc26-9d7e509219af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wki-sose25)",
   "language": "python",
   "name": "wki-sose25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
