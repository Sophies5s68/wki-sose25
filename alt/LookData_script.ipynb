{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b60d2c-df95-47c4-9a97-9400ff2e2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Notebook um sich die Daten genauer anzuschauen'\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import preprocess\n",
    "import importlib\n",
    "import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58986a89-758f-4664-9d87-6cd454988532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = \"../shared_data/training_mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33513c34-51f4-4cf7-bc41-382f76b0dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f13b6f-45f6-4dd5-b8ba-4a944b3a7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_channels = channels[0]  # Use the first sample as reference\n",
    "all_same = True  # Flag to track if all are the same\n",
    "\n",
    "for i, ch in enumerate(channels):\n",
    "    if ch != reference_channels:\n",
    "        all_same = False\n",
    "        print(f\"Sample ID {ids[i]} has different channels.\")\n",
    "        extra = set(ch) - set(reference_channels)\n",
    "        missing = set(reference_channels) - set(ch)\n",
    "        if extra:\n",
    "            print(f\"  Extra channels: {extra}\")\n",
    "        if missing:\n",
    "            print(f\"  Missing channels: {missing}\")\n",
    "\n",
    "if all_same:\n",
    "    print(\"Every sample has the same channels.\")\n",
    "    print(reference_channels)\n",
    "    print(len(reference_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bd596-5727-4665-b11e-b822c7bf1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "print(f\"found {n_files} files\")\n",
    "\n",
    "index = 0\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    CNN_dataset.create_cnn_dataset_map(ids, channels, data, sampling_frequencies, reference_systems, eeg_labels, i)\n",
    "    print(f\"created dataset {index}\")\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f424cf5-76ce-4664-ae1b-87071235333d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e68209-9a93-4681-b94c-4ba19b1820ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from wettbewerb import get_3montages\n",
    "\n",
    "# Pakete aus dem Vorlesungsbeispiel\n",
    "import mne\n",
    "from scipy import signal as sig\n",
    "import ruptures as rpt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from CNN_model import CNN_EEG\n",
    "from preprocess import process_without_mne\n",
    "from features import feature_extraction\n",
    "from CNN_dataset import window_data_evaluate, create_fixed_grid_maps\n",
    "from glob import glob\n",
    "\n",
    "###Signatur der Methode (Parameter und Anzahl return-Werte) darf nicht verändert werden\n",
    "def predict_labels(channels : List[str], data : np.ndarray, fs : float, reference_system: str, model_name : str='model.json') -> Dict[str,Any]:\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : List[str]\n",
    "        Namen der übergebenen Kanäle\n",
    "    data : ndarray\n",
    "        EEG-Signale der angegebenen Kanäle\n",
    "    fs : float\n",
    "        Sampling-Frequenz der Signale.\n",
    "    reference_system :  str\n",
    "        Welches Referenzsystem wurde benutzt, \"Bezugselektrode\", nicht garantiert korrekt!\n",
    "    model_name : str\n",
    "        Name eures Models,das ihr beispielsweise bei Abgabe genannt habt. \n",
    "        Kann verwendet werden um korrektes Model aus Ordner zu laden\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : Dict[str,Any]\n",
    "        enthält Vorhersage, ob Anfall vorhanden und wenn ja wo (Onset+Offset)\n",
    "    '''\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Euer Code ab hier  \n",
    "\n",
    "    # Initialisiere Return (Ergebnisse)\n",
    "    seizure_present = True # gibt an ob ein Anfall vorliegt\n",
    "    seizure_confidence = 0.5 # gibt die Unsicherheit des Modells an (optional)\n",
    "    onset = 4.2   # gibt den Beginn des Anfalls an (in Sekunden)\n",
    "    onset_confidence = 0.99 # gibt die Unsicherheit bezüglich des Beginns an (optional)\n",
    "    offset = 999999  # gibt das Ende des Anfalls an (optional)\n",
    "    offset_confidence = 0   # gibt die Unsicherheit bezüglich des Endes an (optional)\n",
    "\n",
    "    # Modell Aufsetzen\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device(\"cpu\")\n",
    "    '''\n",
    "    model = torch.load(model_name, map_location=device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    '''\n",
    "    #Daten vorbereiten\n",
    "    window_size = 4.0\n",
    "    step_size = 1\n",
    "    standard_channels = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "    n_nodes = len(standard_channels)\n",
    "\n",
    "    processed_input = process_without_mne(data, fs, channels, reference_system, fs)\n",
    "    \n",
    "    channel_map = {ch: idx for idx, ch in enumerate(channels)}\n",
    "    pad_data = np.zeros((n_nodes, processed_input.shape[1]))\n",
    "    for j, ch in enumerate(standard_channels):\n",
    "        if ch in channel_map:\n",
    "            pad_data[j] = processed_input[channel_map[ch]]\n",
    "    \n",
    "    windows = window_data_evaluate(pad_data, fs, window_size, step_size)\n",
    "    data_for_class = []\n",
    "    # Feature extraction and brain map calculation\n",
    "    for win in windows:\n",
    "        features = feature_extraction(win, fs) # shape: (n_channels, n_features)\n",
    "        assert not np.isnan(features).any(), \"NaN in features!\"\n",
    "        brain_map = create_fixed_grid_maps(features, channels)\n",
    "        assert not np.isnan(brain_map).any(), \"NaN in brain_map!\"\n",
    "        x = torch.tensor(brain_map, dtype = torch.float)\n",
    "        data_for_class.append(x)\n",
    "        \n",
    "\n",
    "    # Klassifikation\n",
    "    predictions_per_window =[]\n",
    "    with torch.no_grad():\n",
    "        for feature_map in data_for_class:\n",
    "            feature_map = feature_map.unsqueeze(0).to(device)\n",
    "            #output = model(feature_map)\n",
    "            #predicted_class = torch.argmax(output, dim=1).item()\n",
    "            predicted_class = predictions_ensemble(feature_map,model_name,device)\n",
    "            predictions_per_window.append(predicted_class)\n",
    "    \n",
    "    seizure_present = False\n",
    "    '''\n",
    "    if 1 in predictions_per_window:\n",
    "        seizure_present = True\n",
    "        first_idx = predictions_per_window.index(1)\n",
    "        time_first = first_idx * step_size\n",
    "        onset = time_first\n",
    "    '''\n",
    "    for i in range(len(predictions_per_window) - 1):\n",
    "        if predictions_per_window[i] == 1 and predictions_per_window[i + 1] == 1:\n",
    "            seizure_present = True\n",
    "            time_first = i * step_size\n",
    "            onset = time_first\n",
    "            break\n",
    "    '''\n",
    "    # Hier könnt ihr euer vortrainiertes Modell laden (Kann auch aus verschiedenen Dateien bestehen)\n",
    "    model = MyCNN()\n",
    "    model.load_state_dict(torch.load(model_name, map_location='cpu'))\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    # Wende Beispielcode aus Vorlesung an \n",
    "    \n",
    "    _montage, _montage_data, _is_missing = get_3montages(channels, data)\n",
    "    signal_std = np.zeros(len(_montage))\n",
    "    for j, signal_name in enumerate(_montage):\n",
    "        # Ziehe erste Montage des EEG\n",
    "        signal = _montage_data[j]\n",
    "        # Wende Notch-Filter an um Netzfrequenz zu dämpfen\n",
    "        signal_notch = mne.filter.notch_filter(x=signal, Fs=fs, freqs=np.array([50.,100.]), n_jobs=2, verbose=False)\n",
    "        # Wende Bandpassfilter zwischen 0.5Hz und 70Hz um Rauschen aus dem Signal zu filtern\n",
    "        signal_filter = mne.filter.filter_data(data=signal_notch, sfreq=fs, l_freq=0.5, h_freq=70.0, n_jobs=2, verbose=False)\n",
    "        \n",
    "        # Berechne short time fourier transformation des Signal: signal_filtered = filtered signal of channel, fs = sampling frequency, nperseg = length of each segment\n",
    "        # Output f= array of sample frequencies, t = array of segment times, Zxx = STFT of signal\n",
    "        f, t, Zxx = sig.stft(signal_filter, fs, nperseg=fs * 3)\n",
    "        # Berechne Schrittweite der Frequenz\n",
    "        df = f[1] - f[0]\n",
    "        # Berechne Engergie (Betrag) basierend auf Real- und Imaginärteil der STFT\n",
    "        E_Zxx = np.sum(Zxx.real ** 2 + Zxx.imag ** 2, axis=0) * df\n",
    "        \n",
    "        signal_std[j] = np.std(signal_filter)\n",
    "\n",
    "\n",
    "\n",
    "        # Erstelle neues Array in der ersten Iteration pro Patient\n",
    "        if j == 0:\n",
    "            # Initilisiere Array mit Energiesignal des ersten Kanals\n",
    "            E_array = np.array(E_Zxx)\n",
    "        else:\n",
    "            # Füge neues Energiesignal zu vorhandenen Kanälen hinzu (stack it)\n",
    "            E_array = np.vstack((E_array, np.array(E_Zxx)))\n",
    "            \n",
    "    # Berechne Feature zur Seizure Detektion\n",
    "    signal_std_max = signal_std.max()\n",
    "    # Klassifiziere Signal\n",
    "    seizure_present = signal_std_max>th_opt\n",
    "    \n",
    "    # Berechne Gesamtenergie aller Kanäle für jeden Zeitppunkt\n",
    "    E_total = np.sum(E_array, axis=0)\n",
    "    # Berechne Stelle der maximalen Energie\n",
    "    max_index = E_total.argmax()\n",
    "\n",
    "    # Berechne \"changepoints\" der Gesamtenergie\n",
    "    # Falls Maximum am Anfang des Signals ist muss der Onset ebenfalls am Anfang sein und wir können keinen \"changepoint\" berechnen\n",
    "    if max_index == 0:\n",
    "        onset = 0.0\n",
    "        onset_confidence = 0.2\n",
    "        \n",
    "    else:\n",
    "        # Berechne \"changepoint\" mit dem ruptures package\n",
    "        # Setup für  \"linearly penalized segmentation method\" zur Detektion von changepoints im Signal mi rbf cost function\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(E_total)\n",
    "        # Berechne sortierte Liste der changepoints, pen = penalty value\n",
    "        result = algo.predict(pen=10)\n",
    "        #Indices sind ums 1 geshiftet\n",
    "        result1 = np.asarray(result) - 1\n",
    "        # Selektiere changepoints vor Maximum\n",
    "        result_red = result1[result1 < max_index]\n",
    "        # Falls es mindestens einen changepoint gibt nehmen wir den nächsten zum Maximum\n",
    "        if len(result_red)<1:\n",
    "            # Falls keine changepoint gefunden wurde raten wir, dass er \"nahe\" am Maximum ist\n",
    "            print('No changepoint, taking maximum')\n",
    "            onset_index = max_index\n",
    "        else:\n",
    "            # Der changepoint entspricht gerade dem Onset \n",
    "            onset_index = result_red[-1]\n",
    "        # Gebe Onset zurück\n",
    "        onset = t[onset_index]      \n",
    "     \n",
    "     \n",
    "    '''\n",
    "#------------------------------------------------------------------------------  \n",
    "    prediction = {\"seizure_present\":seizure_present,\"seizure_confidence\":seizure_confidence,\n",
    "                   \"onset\":onset,\"onset_confidence\":onset_confidence,\"offset\":offset,\n",
    "                   \"offset_confidence\":offset_confidence}\n",
    "  \n",
    "    return prediction # Dictionary mit prediction - Muss unverändert bleiben!\n",
    "                               \n",
    "                               \n",
    "        \n",
    "def predictions_ensemble(feature,model_name,device):\n",
    "    \n",
    "    file_paths = sorted([os.path.join(model_name, f) for f in os.listdir(model_name) if f.endswith(\".pth\")])\n",
    "\n",
    "    probas = torch.zeros(2).to(device)  # 2 Klassen\n",
    "    with torch.no_grad():\n",
    "        for path in file_paths:\n",
    "            model = torch.load(path, map_location=device)\n",
    "            model.eval()\n",
    "            output = model(feature)  # shape: [1, 2]\n",
    "            probas += torch.softmax(output.squeeze(), dim=0)  # → shape: [2]\n",
    "\n",
    "    prediction = probas / len(file_paths)  # shape: [2]\n",
    "    y_pred = (prediction[1] > 0.5).long()  # ← sicher!\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be24367d-a342-4c17-a1d5-eccd50a5550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(\"../shared_data/training_mini\", 99)\n",
    "print(predict_labels(channels[0],data[0],sampling_frequencies[0],reference_systems[0],\"models_strat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbb7cf-78d8-4b95-b127-ff2357b6c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "print(f\"found {n_files} files\")\n",
    "\n",
    "index = 0\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    CNN_dataset.create_cnn_dataset_map(ids, channels, data, sampling_frequencies, reference_systems, eeg_labels, i)\n",
    "    print(f\"created dataset {index}\")\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78630c8a-5990-4cb9-911c-c347132bf62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wettbewerb import load_references\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "\n",
    "print(f\"found {n_files} files\")\n",
    "\n",
    "index = 0\n",
    "positive_data = []\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    df = pd.DataFrame({\n",
    "    'ids': ids,  \n",
    "    'channels': channels,\n",
    "    'data': data,\n",
    "    'fs' : sampling_frequencies,\n",
    "    'ref' : reference_systems,\n",
    "    'label' : eeg_labels\n",
    "    })\n",
    "    \n",
    "    df_label_1 = df[df['label'].apply(lambda x: x[0] == 1)]\n",
    "    positive_data.append(df_label_1)\n",
    "    index = index +1\n",
    "    \n",
    "df_label_1_gesamt = pd.concat(positive_data, ignore_index=True)\n",
    "df_label_1_gesamt.to_pickle(\"positive_daten.pkl\")\n",
    "\n",
    "df = pd.read_pickle(\"positive_daten.pkl\")\n",
    "min_fs = df['fs'].min()\n",
    "for i, row in df.iterrows():\n",
    "    orig_fs = row['fs']\n",
    "    new_data = []\n",
    "    if orig_fs > min_fs:\n",
    "        for ind, channel in enumerate(row['data']):\n",
    "            orig_len = len(channel)\n",
    "\n",
    "            new_len = int(orig_len * min_fs / orig_fs)\n",
    "            new_channel = sc.signal.resample(channel, new_len)\n",
    "            new_data.append(new_channel)\n",
    "        df.at[i, 'data'] = np.asarray(new_data)\n",
    "        df.at[i, 'fs'] = min_fs \n",
    "    \n",
    "\n",
    "nyq = 0.5 * min_fs\n",
    "low = 1 / nyq\n",
    "high = 120 / nyq\n",
    "b, a = signal.butter(4, [low, high], btype='band')\n",
    "\n",
    "w0 = 60 / (min_fs / 2)  # Normierte Frequenz\n",
    "b1, a1 = signal.iirnotch(w0, 30)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    orig_data = row['data']\n",
    "    band_data = signal.filtfilt(b,a,orig_data)\n",
    "    notch_data = signal.filtfilt(b1,a1,band_data)\n",
    "    df.at[i, 'data'] = notch_data\n",
    "    \n",
    "df.to_pickle(\"positive_filtered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301e31c-a523-4f9e-b27e-836633d56fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"positive_filtered.pkl\")\n",
    "print(df.shape)\n",
    "df.to_csv(\"pos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54315e9e-0367-48cb-bfcc-e87e70c73e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "\n",
    "df = pd.read_csv(\"positive_daten.csv\")\n",
    "min_fs = df['fs'].min()\n",
    "for i, row in df.iterrows():\n",
    "    orig_fs = row['fs']\n",
    "    if orig_fs > min_fs:\n",
    "        orig_data = row['data']\n",
    "        orig_len = len(orig_data)\n",
    "        \n",
    "        new_len = int(orig_len * min_fs / orig_fs)\n",
    "        new_data = sc.signal.resample(orig_data, new_len)\n",
    "        df.at[i, 'data'] = new_data\n",
    "        df.at[i, 'fs'] = min_fs \n",
    "    \n",
    "\n",
    "nyq = 0.5 * min_fs\n",
    "low = 1 / nyq\n",
    "high = 120 / nyq\n",
    "b, a = signal.butter(4, [low, high], btype='band')\n",
    "\n",
    "w0 = 60 / (min_fs / 2)  # Normierte Frequenz\n",
    "b1, a1 = signal.iirnotch(w0, 30)\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    orig_data = row['data']\n",
    "    band_data = signal.filtfilt(b,a,orig_data)\n",
    "    notch_data = signal.filtfilt(b1,a1,band_data)\n",
    "    df.at[i, 'data'] = notch_data\n",
    "    \n",
    "df_label_1_gesamt.to_csv(\"positive_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5fa09-b36f-476c-b7d7-6710935410ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"positive_daten.csv\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb2ef08-a9fc-4944-a99a-894fa2ac75fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2421, 6)\n",
      "Gefilterte Daten gespeichert unter: positive_filtered_100Hz.pkl\n"
     ]
    }
   ],
   "source": [
    "from wettbewerb import load_references\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "\n",
    "# Daten laden\n",
    "df = pd.read_pickle(\"positive_daten.pkl\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "# Ziel-Samplingrate\n",
    "min_fs = 100\n",
    "\n",
    "# Resampling\n",
    "for i, row in df.iterrows():\n",
    "    orig_fs = row['fs']\n",
    "    if orig_fs > min_fs:\n",
    "        new_data = []\n",
    "        for channel in row['data']:\n",
    "            new_len = int(len(channel) * min_fs / orig_fs)\n",
    "            new_channel = signal.resample(channel, new_len)\n",
    "            new_data.append(new_channel)\n",
    "        df.at[i, 'data'] = np.asarray(new_data)\n",
    "        df.at[i, 'fs'] = min_fs\n",
    "\n",
    "# Bandpass-Grenzen anpassen\n",
    "nyq = 0.5 * min_fs\n",
    "lowcut = 1\n",
    "highcut = min(120, nyq - 1)  # muss < nyq bleiben\n",
    "low = lowcut / nyq\n",
    "high = highcut / nyq\n",
    "\n",
    "# Filter entwerfen\n",
    "b_band, a_band = signal.butter(4, [low, high], btype='band')\n",
    "\n",
    "\n",
    "# Filter anwenden\n",
    "for i, row in df.iterrows():\n",
    "    data = row['data']  # shape: (channels, samples)\n",
    "    band_data = signal.filtfilt(b_band, a_band, data, axis=1)\n",
    "    df.at[i, 'data'] = band_data\n",
    "\n",
    "# Speichern\n",
    "df.to_pickle(\"positive_filtered_100Hz.pkl\")\n",
    "print(\"Gefilterte Daten gespeichert unter: positive_filtered_100Hz.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2edd8-5e1d-4b68-b12c-9f33ef78b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"positive_daten.pkl\")\n",
    "print(df.shape)\n",
    "print(df.loc[1, 'data'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a5264-0863-4e67-b358-d6347456a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Hole Daten und Sampling-Rate\n",
    "data = df.loc[1, 'data']       # shape: (channels, samples)\n",
    "fs = df.loc[1, 'fs']           # Sampling-Rate in Hz\n",
    "\n",
    "channels, samples = data.shape\n",
    "t = np.arange(samples) / fs    # Zeitachse (optional)\n",
    "\n",
    "# Frequenzachse für FFT\n",
    "freqs = np.fft.rfftfreq(samples, d=1/fs)\n",
    "\n",
    "# Erzeuge das Plot-Fenster\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Für jeden Kanal das Spektrum berechnen und plotten\n",
    "for ch in range(channels):\n",
    "    signal = data[ch]\n",
    "    fft_vals = np.fft.rfft(signal)\n",
    "    magnitude = np.abs(fft_vals)\n",
    "    plt.plot(freqs, magnitude, label=f'Kanal {ch}')\n",
    "\n",
    "plt.title('Frequenzspektrum pro Kanal')\n",
    "plt.xlabel('Frequenz [Hz]')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.ylim(0,0.05)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f4cd0-33ab-4b9e-bc0f-054854bc30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_dataset\n",
    "from wettbewerb import load_references, get_3montages\n",
    "import os\n",
    "\n",
    "train_folder = \"../shared_data/training\"\n",
    "files = [f for f in os.listdir(train_folder) if f.endswith('.mat')]\n",
    "n_files = len(files)\n",
    "\n",
    "print(f\"found {n_files} files\")\n",
    "window_configs = [(5,5),(10,10),(10,5),(20,20),(20,10),(30,30),(30,15),(60,60),(60,30)]\n",
    "index = 0\n",
    "for i in range(0, n_files, 100):\n",
    "    ids, channels, data, sampling_frequencies, reference_systems, eeg_labels = load_references(train_folder, i)\n",
    "    CNN_dataset.create_multiple_cnn_datasets(ids, channels, data, sampling_frequencies, reference_systems, eeg_labels,index,window_configs, base_output_dir=\"datasets\")\n",
    "    print(f\"\\n created datasets {index}\")\n",
    "    index = index + 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0250bf-d374-4425-adb4-c52c662726e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 63 files.\n",
      "Convert to numpy arrays\n",
      "Compute means\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Power per Band – Label 0\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar(\u001b[43mim\u001b[49m, ax\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mgcf()\u001b[38;5;241m.\u001b[39maxes, shrink\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# Dataset path\n",
    "test_dataset = \"datasets/win10_step10\"\n",
    "file_paths = sorted(glob(os.path.join(test_dataset, \"*.pt\")))\n",
    "print(f\"🔍 Found {len(file_paths)} files.\")\n",
    "\n",
    "power_data_label0 = []\n",
    "power_data_label1 = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    data = torch.load(file_path)\n",
    "    for x, y, gruppe in data:\n",
    "        power = x[:6].numpy()  # shape: (5, 5, 5)\n",
    "        if y.item() == 0:\n",
    "            power_data_label0.append(power)\n",
    "        elif y.item() == 1:\n",
    "            power_data_label1.append(power)\n",
    "print(\"Convert to numpy arrays\")\n",
    "# Convert to numpy arrays\n",
    "power_array_0 = np.stack(power_data_label0) if power_data_label0 else np.empty((0, 5, 5, 5))\n",
    "power_array_1 = np.stack(power_data_label1) if power_data_label1 else np.empty((0, 5, 5, 5))\n",
    "print(\"Compute means\")\n",
    "# Compute means\n",
    "mean_power_0 = np.mean(power_array_0, axis=0) if len(power_array_0) > 0 else None\n",
    "mean_power_1 = np.mean(power_array_1, axis=0) if len(power_array_1) > 0 else None\n",
    "\n",
    "# Shared color scale\n",
    "vmin = min(np.min(mean_power_0), np.min(mean_power_1))\n",
    "vmax = max(np.max(mean_power_0), np.max(mean_power_1))\n",
    "\n",
    "bands = [\"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Gamma\"]\n",
    "\n",
    "# Plot label 0\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(mean_power_0[i], cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "    plt.title(f\"{bands[i]} (Label 0)\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Mean Power per Band – Label 0\", fontsize=14)\n",
    "plt.colorbar(im, ax=plt.gcf().axes, shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot label 1\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(mean_power_1[i], cmap=\"viridis\", vmin=vmin, vmax=vmax)\n",
    "    plt.title(f\"{bands[i]} (Label 1)\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Mean Power per Band – Label 1\", fontsize=14)\n",
    "plt.colorbar(im, ax=plt.gcf().axes, shrink=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515a6f1-340e-4b95-8f4f-ed2196825d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "# Load the DataFrame\n",
    "df = pd.read_pickle('positive_filtered.pkl')\n",
    "\n",
    "# Display basic info\n",
    "print(df.info())     # Column types, non-null counts\n",
    "print(df.head())     # First few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c831439-decc-48de-a354-869e4e537c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['class', 'onset_time', 'end_time']] = pd.DataFrame(df['label'].tolist(), index=df.index)\n",
    "df['onset_sample'] = (df['onset_time'] * df['fs']).astype(int)\n",
    "MAX_LEN = 1000\n",
    "N_CHANNELS = 19\n",
    "import numpy as np\n",
    "\n",
    "def pad_data(x, max_len=MAX_LEN, n_channels=N_CHANNELS):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Fix shape if needed\n",
    "    if x.ndim != 2:\n",
    "        x = np.atleast_2d(x)\n",
    "    \n",
    "    # Ensure correct number of channels\n",
    "    if x.shape[0] != n_channels:\n",
    "        raise ValueError(f\"Expected {n_channels} channels, got {x.shape[0]}\")\n",
    "    \n",
    "    # Pad or truncate time dimension\n",
    "    if x.shape[1] > max_len:\n",
    "        x = x[:, :max_len]\n",
    "    elif x.shape[1] < max_len:\n",
    "        pad_width = max_len - x.shape[1]\n",
    "        x = np.pad(x, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    \n",
    "    return x\n",
    "df_consistent = df[df['data'].apply(lambda x: np.array(x).shape[0] == 19)].reset_index(drop=True)\n",
    "X = np.stack(df_consistent['data'].apply(lambda x: pad_data(x)))\n",
    "y = df_consistent['onset_sample'].values\n",
    "X = np.transpose(X, (0, 2, 1))  # (samples, time, channels)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # last time step\n",
    "        return self.fc(out).squeeze()\n",
    "\n",
    "model = LSTMRegressor(input_size=X.shape[2])\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                              torch.tensor(y_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
    "    mse = ((preds - y_test) ** 2).mean()\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "\n",
    "    i = 0  # index of a sample to plot\n",
    "signal = X_test[i]  # shape: (time, channels)\n",
    "signal_ch0 = signal[:, 0]  # visualize one channel\n",
    "\n",
    "true_onset = int(y_test[i])\n",
    "pred_onset = int(preds[i])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(signal_ch0, label='EEG Channel 0')\n",
    "plt.axvline(true_onset, color='green', linestyle='--', label='True Onset')\n",
    "plt.axvline(pred_onset, color='red', linestyle='--', label='Predicted Onset')\n",
    "plt.legend()\n",
    "plt.title(\"EEG Signal with True vs. Predicted Onset\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73054bc5-bdc7-4e7f-bdce-8173f4e254ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wki-sose25)",
   "language": "python",
   "name": "wki-sose25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
