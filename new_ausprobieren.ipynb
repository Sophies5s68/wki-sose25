{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f385f6a-f913-40a9-a0d0-0b50fbe42dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Ich probier jetzt jeden Schritt nochmal von vorne und schau mir den Schritt nochmal genauer an'\n",
    "\n",
    "from wettbewerb import load_references, get_6montages\n",
    "from new_preprocess import preprocess_signal_with_montages\n",
    "\n",
    "\n",
    "ids, channels_list, data_list, fs_list, ref_list, label_list = load_references(folder=\"../shared_data/training\", idx=0)\n",
    "for i in range(100):\n",
    "    #montage_names, montage_data, missing = get_6montages(channels_list[i], data_list[i])\n",
    "    #print(f\"{ids[i]}:{montage_names}:{montage_data.shape}\\n {fs_list[i]}\")\n",
    "    #if missing:\n",
    "        #print(\"Warning: Montage missing, data may be incomplete.\")\n",
    "    #print (f\"{ids[i]}\",label_list[i])\n",
    "    processed_signal, montage_missing = preprocess_signal_with_montages(channels_list[i], data_list[i], 256, fs_list[i])\n",
    "    print(f\"{ids[i]}:\",processed_signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdc1a4-54fe-4817-b565-0d19f94762ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wettbewerb import EEGDataset\n",
    "\n",
    "dataset = EEGDataset(\"../shared_data/training\")\n",
    "labels = dataset.get_labels()\n",
    "\n",
    "# Count seizure / non-seizure\n",
    "seizure_count = sum(1 for l in labels if l[0])\n",
    "non_seizure_count = len(labels) - seizure_count\n",
    "\n",
    "print(f\"Total: {len(labels)}\")\n",
    "print(f\"Seizures: {seizure_count}\")\n",
    "print(f\"Non-Seizures: {non_seizure_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d046948-7f78-4882-81c4-19a37e08f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!/6213] Processed: 6213 | Skipped: 0\n"
     ]
    }
   ],
   "source": [
    "from wettbewerb import EEGDataset\n",
    "import os\n",
    "import torch \n",
    "from new_preprocess import preprocess_signal_with_montages\n",
    "dataset = EEGDataset(\"../shared_data/training\")\n",
    "save_folder = \"preprocessed_data\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "processed_count = 0\n",
    "skipped_count = 0\n",
    "total = len(dataset)\n",
    "\n",
    "for i in range(total):\n",
    "    ids, channels, data, fs, ref, label = dataset[i]\n",
    "\n",
    "    montage_names, processed_signal, montage_missing, resampled_fs = preprocess_signal_with_montages(\n",
    "        channels, data, target_fs=256, original_fs=fs, ids=ids\n",
    "    )\n",
    "\n",
    "    if montage_missing:\n",
    "        skipped_count += 1\n",
    "        print(f\"[{i+1}/{total}] Skipping {ids} (montage missing)\")\n",
    "        continue\n",
    "\n",
    "    save_path = os.path.join(save_folder, f\"{ids}.pt\")\n",
    "    torch.save((processed_signal, label, ids, montage_names, resampled_fs), save_path)\n",
    "    processed_count += 1\n",
    "    print(f\"[{i+1}/{total}] Processed: {processed_count} | Skipped: {skipped_count}\", end='\\r')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c0c4a3-d55d-4088-a3b1-ed0ef2c21959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/6213] Processed aaaaasdq_s004_t001 with 340 windows.s.\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m seizure_label, seizure_onset, seizure_offset \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 1. Preprocess\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m montage_names, processed_signal, montage_missing, new_fs \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_signal_with_montages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_fs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_fs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meeg_id\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m montage_missing:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meeg_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (montage missing)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/wki-sose25/new_preprocess.py:53\u001b[0m, in \u001b[0;36mpreprocess_signal_with_montages\u001b[0;34m(channels, data, target_fs, original_fs, ids)\u001b[0m\n\u001b[1;32m     51\u001b[0m montage_data \u001b[38;5;241m=\u001b[39m bandpass_filter_iir_filtfilt(montage_data, fs\u001b[38;5;241m=\u001b[39moriginal_fs)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Signale werden auf die gleiche Samplingrate fs = 256 resampled \u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m montage_data \u001b[38;5;241m=\u001b[39m \u001b[43mresample_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmontage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_fs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_fs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m montage_names, montage_data, montage_missing, target_fs\n",
      "File \u001b[0;32m~/wki-sose25/new_preprocess.py:14\u001b[0m, in \u001b[0;36mresample_signal\u001b[0;34m(sig, original_fs, target_fs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sps\u001b[38;5;241m.\u001b[39mresample(sig, n_samples)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack([sps\u001b[38;5;241m.\u001b[39mresample(ch, n_samples) \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m sig])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignal muss 1D oder 2D sein.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/wki-sose25/new_preprocess.py:14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sps\u001b[38;5;241m.\u001b[39mresample(sig, n_samples)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[43msps\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m sig])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSignal muss 1D oder 2D sein.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/wki-sose25/lib/python3.8/site-packages/scipy/signal/_signaltools.py:3107\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, num, t, axis, window, domain)\u001b[0m\n\u001b[1;32m   3104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m domain \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   3105\u001b[0m     \u001b[38;5;66;03m# Forward transform\u001b[39;00m\n\u001b[1;32m   3106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m real_input:\n\u001b[0;32m-> 3107\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43msp_fft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3108\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Full complex FFT\u001b[39;00m\n\u001b[1;32m   3109\u001b[0m         X \u001b[38;5;241m=\u001b[39m sp_fft\u001b[38;5;241m.\u001b[39mfft(x, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.conda/envs/wki-sose25/lib/python3.8/site-packages/scipy/fft/_backend.py:25\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/wki-sose25/lib/python3.8/site-packages/scipy/fft/_pocketfft/basic.py:62\u001b[0m, in \u001b[0;36mr2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid number of data points (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m) specified\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                      \u001b[38;5;241m.\u001b[39mformat(tmp\u001b[38;5;241m.\u001b[39mshape[axis]))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilised\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from wettbewerb import EEGDataset\n",
    "from new_preprocess import preprocess_signal_with_montages\n",
    "from new_features import window_eeg_data, feature_extraction_window  # your modules\n",
    "import os, torch\n",
    "import numpy as np\n",
    "\n",
    "window_size = 4  # seconds\n",
    "step_size = 2    # seconds\n",
    "\n",
    "dataset = EEGDataset(\"../shared_data/training\")\n",
    "save_folder = f\"montage_datasets/win{window_size}_step{step_size}\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    eeg_id, channels, raw_data, fs, _, label = dataset[i]\n",
    "    seizure_label, seizure_onset, seizure_offset = label\n",
    "\n",
    "    # 1. Preprocess\n",
    "    montage_names, processed_signal, montage_missing, new_fs = preprocess_signal_with_montages(\n",
    "        channels, raw_data, target_fs=256, original_fs=fs, ids=eeg_id\n",
    "    )\n",
    "\n",
    "    if montage_missing:\n",
    "        print(f\"Skipping {eeg_id} (montage missing)\")\n",
    "        continue\n",
    "\n",
    "    # 2. Windowing + labeling\n",
    "    windows, labels, timestamps = window_eeg_data(\n",
    "        processed_signal, resampled_fs=new_fs,\n",
    "        seizure_onset=seizure_onset,\n",
    "        seizure_offset=seizure_offset,\n",
    "        window_size=window_size,\n",
    "        step_size=step_size\n",
    "    )\n",
    "\n",
    "    # 3. Feature extraction per window\n",
    "    for idx, (window, lbl, ts) in enumerate(zip(windows, labels, timestamps)):\n",
    "        features = feature_extraction_window(window, new_fs)\n",
    "        save_path = os.path.join(save_folder, f\"{eeg_id}_win{idx}_lbl{lbl}.pt\")\n",
    "        torch.save((features, lbl, eeg_id, ts), save_path)\n",
    "\n",
    "    print(f\"[{i+1}/{len(dataset)}] Processed {eeg_id} with {len(windows)} windows.\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0600ae54-6c8b-4551-82d9-6e7ec1c6aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertig. 407127 Dateien verarbeitet.\n",
      "win8_step8\n",
      "Fertig. 647245 Dateien verarbeitet.\n",
      "win10_step5\n",
      "Fertig. 325719 Dateien verarbeitet.\n",
      "win10_step10\n",
      "Fertig. 210412 Dateien verarbeitet.\n",
      "win30_step15\n",
      "Fertig. 319609 Dateien verarbeitet.\n",
      "win20_step10\n",
      "Fertig. 107275 Dateien verarbeitet.\n",
      "win30_step30\n",
      "Fertig. 3257654 Dateien verarbeitet.\n",
      "win4_step1\n",
      "Fertig. 161898 Dateien verarbeitet.\n",
      "win20_step20\n",
      "Fertig. 1630251 Dateien verarbeitet.\n",
      "win4_step2\n",
      "Fertig. 811015 Dateien verarbeitet.\n",
      "win8_step4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "def split_features(feature_tensor):\n",
    "    \"\"\"\n",
    "    Trennt Features in spektral (0-9) und zeitlich (10-14)\n",
    "    \"\"\"\n",
    "    spectral = feature_tensor[..., :10]         # Indizes 0-9\n",
    "    temporal = feature_tensor[..., 10:15]       # Indizes 10-14\n",
    "    return spectral, temporal\n",
    "\n",
    "def process_feature_files(load_dir, save_dir_spectral, save_dir_temporal):\n",
    "    os.makedirs(save_dir_spectral, exist_ok=True)\n",
    "    os.makedirs(save_dir_temporal, exist_ok=True)\n",
    "\n",
    "    feature_files = glob(os.path.join(load_dir, \"*.pt\"))\n",
    "\n",
    "    for file in feature_files:\n",
    "        data = torch.load(file)\n",
    "\n",
    "        if isinstance(data, tuple):\n",
    "            features, label, eeg_id, ts = data\n",
    "        elif isinstance(data, dict):\n",
    "            features = data['features']\n",
    "            label = data['label']\n",
    "            eeg_id = data['eeg_id']\n",
    "            ts = data['timestamp']\n",
    "        else:\n",
    "            print(f\"Unbekanntes Format: {file}\")\n",
    "            continue\n",
    "\n",
    "        # in numpy falls tensor\n",
    "        if isinstance(features, torch.Tensor):\n",
    "            features = features.numpy()\n",
    "\n",
    "        # flach oder Matrix?\n",
    "        if features.ndim == 1:\n",
    "            n_channels = 18  # oder dein tatsächlicher Wert\n",
    "            features = features.reshape(n_channels, -1)\n",
    "\n",
    "        spec_feat, time_feat = split_features(features)\n",
    "\n",
    "        # Optional: flatten\n",
    "        spec_feat_flat = spec_feat.flatten()\n",
    "        time_feat_flat = time_feat.flatten()\n",
    "\n",
    "        base_name = os.path.basename(file)\n",
    "\n",
    "        # Speichern\n",
    "        torch.save((spec_feat_flat, label, eeg_id, ts), os.path.join(save_dir_spectral, base_name))\n",
    "        torch.save((time_feat_flat, label, eeg_id, ts), os.path.join(save_dir_temporal, base_name))\n",
    "\n",
    "    print(f\"Fertig. {len(feature_files)} Dateien verarbeitet.\")\n",
    "\n",
    "# Beispiel:\n",
    "ordner = \"/home/jupyter-wki_team_3/wki-sose25/montage_datasets/\"\n",
    "unterordner = [f for f in os.listdir(ordner) if os.path.isdir(os.path.join(ordner, f)) and not f.startswith('.')]\n",
    "    \n",
    "for config in unterordner:\n",
    "    \n",
    "    load_dir = \"montage_datasets/\"+ config\n",
    "    save_dir_spectral = \"data_features_sep/spectral/\" + config\n",
    "    save_dir_temporal = \"data_features_sep/temporal/\" + config\n",
    "\n",
    "    process_feature_files(load_dir, save_dir_spectral, save_dir_temporal)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da117929-d02f-4838-b337-bcb0150ccbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wki-sose25)",
   "language": "python",
   "name": "wki-sose25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
